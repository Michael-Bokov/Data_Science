{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch==1.13.0 torchtext==0.14.0 torchdata==0.5.0\n!pip install scipy==1.7.3 scikit-learn==1.0.2","metadata":{"id":"GWRS3kURlvDb","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"086557e3-9ab4-42ac-96c2-eede4b664b3c","execution":{"iopub.status.busy":"2023-09-28T13:27:09.169534Z","iopub.execute_input":"2023-09-28T13:27:09.169892Z","iopub.status.idle":"2023-09-28T13:29:42.449569Z","shell.execute_reply.started":"2023-09-28T13:27:09.169863Z","shell.execute_reply":"2023-09-28T13:29:42.448446Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting torch==1.13.0\n  Downloading torch-1.13.0-cp310-cp310-manylinux1_x86_64.whl (890.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m890.1/890.1 MB\u001b[0m \u001b[31m702.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting torchtext==0.14.0\n  Downloading torchtext-0.14.0-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting torchdata==0.5.0\n  Downloading torchdata-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==1.13.0) (4.6.3)\nCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==1.13.0)\n  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==1.13.0)\n  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==1.13.0)\n  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==1.13.0)\n  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torchtext==0.14.0) (4.66.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchtext==0.14.0) (2.31.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchtext==0.14.0) (1.23.5)\nRequirement already satisfied: urllib3>=1.25 in /opt/conda/lib/python3.10/site-packages (from torchdata==0.5.0) (1.26.15)\nCollecting portalocker>=2.0.0 (from torchdata==0.5.0)\n  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0) (68.0.0)\nRequirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0) (0.40.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext==0.14.0) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext==0.14.0) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext==0.14.0) (2023.7.22)\nInstalling collected packages: portalocker, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, torch, torchtext, torchdata\n  Attempting uninstall: torch\n    Found existing installation: torch 2.0.0\n    Uninstalling torch-2.0.0:\n      Successfully uninstalled torch-2.0.0\n  Attempting uninstall: torchtext\n    Found existing installation: torchtext 0.15.1\n    Uninstalling torchtext-0.15.1:\n      Successfully uninstalled torchtext-0.15.1\n  Attempting uninstall: torchdata\n    Found existing installation: torchdata 0.6.0\n    Uninstalling torchdata-0.6.0:\n      Successfully uninstalled torchdata-0.6.0\nSuccessfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 portalocker-2.8.2 torch-1.13.0 torchdata-0.5.0 torchtext-0.14.0\nCollecting scipy==1.7.3\n  Downloading scipy-1.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting scikit-learn==1.0.2\n  Downloading scikit_learn-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting numpy<1.23.0,>=1.16.5 (from scipy==1.7.3)\n  Downloading numpy-1.22.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.10/site-packages (from scikit-learn==1.0.2) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn==1.0.2) (3.1.0)\nInstalling collected packages: numpy, scipy, scikit-learn\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.23.5\n    Uninstalling numpy-1.23.5:\n      Successfully uninstalled numpy-1.23.5\n  Attempting uninstall: scipy\n    Found existing installation: scipy 1.11.2\n    Uninstalling scipy-1.11.2:\n      Successfully uninstalled scipy-1.11.2\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.2.2\n    Uninstalling scikit-learn-1.2.2:\n      Successfully uninstalled scikit-learn-1.2.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\nchex 0.1.82 requires numpy>=1.25.0, but you have numpy 1.22.4 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.2 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\ncuml 23.8.0 requires scipy>=1.8.0, but you have scipy 1.7.3 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.2 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.2 which is incompatible.\nesda 2.5.0 requires scipy>=1.9, but you have scipy 1.7.3 which is incompatible.\nfeaturetools 1.27.0 requires scipy>=1.10.0, but you have scipy 1.7.3 which is incompatible.\nfitter 1.6.0 requires pandas<3.0.0,>=2.0.3, but you have pandas 2.0.2 which is incompatible.\nmomepy 0.6.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\npointpats 2.3.0 requires scipy>=1.8.0, but you have scipy 1.7.3 which is incompatible.\npymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.22.4 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\nscikit-image 0.21.0 requires scipy>=1.8, but you have scipy 1.7.3 which is incompatible.\nwoodwork 0.26.0 requires scipy>=1.10.0, but you have scipy 1.7.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed numpy-1.22.4 scikit-learn-1.0.2 scipy-1.7.3\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\n","metadata":{"id":"Jmh0AnoadDmv","execution":{"iopub.status.busy":"2023-09-28T13:31:36.996572Z","iopub.execute_input":"2023-09-28T13:31:36.996943Z","iopub.status.idle":"2023-09-28T13:31:37.001578Z","shell.execute_reply.started":"2023-09-28T13:31:36.996913Z","shell.execute_reply":"2023-09-28T13:31:37.000640Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from torch import nn","metadata":{"id":"v2cc5hmDva0v","execution":{"iopub.status.busy":"2023-09-28T13:31:39.237390Z","iopub.execute_input":"2023-09-28T13:31:39.237788Z","iopub.status.idle":"2023-09-28T13:31:39.242666Z","shell.execute_reply.started":"2023-09-28T13:31:39.237759Z","shell.execute_reply":"2023-09-28T13:31:39.241478Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nfrom torchtext.transforms import ToTensor","metadata":{"id":"RIy0VniAdjK2","execution":{"iopub.status.busy":"2023-09-28T13:31:41.814280Z","iopub.execute_input":"2023-09-28T13:31:41.814930Z","iopub.status.idle":"2023-09-28T13:31:43.160180Z","shell.execute_reply.started":"2023-09-28T13:31:41.814896Z","shell.execute_reply":"2023-09-28T13:31:43.159264Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from torchtext.datasets import IMDB\ntrain_iter = iter(IMDB(split='train'))\nlabels = []\ntexts = []\nfor label, text in train_iter:\n    labels += [label]\n    texts += [text]\n\n# определим список классов в датасете, взяв только уникальные метки,\n# превратив список классов в set и затем обратно в list, и\n# отсортировав их \"для красоты\" с помощью функции sorted\nCLASSES = sorted(list(set(labels)))\nprint(CLASSES)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tjojocDTE1AG","outputId":"6f7dfec1-873d-4627-a549-352b9241da4a","execution":{"iopub.status.busy":"2023-09-28T13:31:45.700284Z","iopub.execute_input":"2023-09-28T13:31:45.701122Z","iopub.status.idle":"2023-09-28T13:32:02.701485Z","shell.execute_reply.started":"2023-09-28T13:31:45.701084Z","shell.execute_reply":"2023-09-28T13:32:02.700566Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"[1, 2]\n","output_type":"stream"}]},{"cell_type":"markdown","source":" Токенайзер -- модель, разделяющая тексты на токены.","metadata":{"id":"SNtCFitKZgqu"}},{"cell_type":"code","source":"from torchtext.data.utils import get_tokenizer\n\n\n# загрузим базовый англоязычный basic_english токенизатор с помощью get_tokenizer\ntokenizer = get_tokenizer('basic_english')","metadata":{"id":"WKzDlWsqZQSy","execution":{"iopub.status.busy":"2023-09-28T14:08:11.440992Z","iopub.execute_input":"2023-09-28T14:08:11.441804Z","iopub.status.idle":"2023-09-28T14:08:11.447097Z","shell.execute_reply.started":"2023-09-28T14:08:11.441769Z","shell.execute_reply":"2023-09-28T14:08:11.445781Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":" Словарь.\n Собираем словарь(проиндексированные токены для векторизации текстов). Будем строить словарь на основе итерирования по токенам по обучающей выборки.\n\n\n","metadata":{"id":"_tzQeKTsZ_LE"}},{"cell_type":"code","source":"from torchtext.vocab import build_vocab_from_iterator\n\n\ndef yield_tokens(data_iter):\n    # итерируясь по данным, токенизируем текст в каждом примере в датасете\n    for label, text in data_iter:\n        yield tokenizer(text)\n\n\n# добавим в словарь специальные токены для паддинга и для out-of-vocabulary слов\nPAD_TOKEN = \"<pad>\"\nUNK_TOKEN = \"<unk>\"\n# выберем максимальную длину последовтаельности\nMAX_LENGTH = 128\n# зададим размер батча\nBATCH_SIZE = 64\n\n# а теперь воспользуемся готовой функцией `build_vocab_from_iterator`\n# для того, чтобы собрать словарь токенов из представленого\n# итератора yield_tokens(train_iter) по текстам обучающей выборки,\n# добавим специальные токены [UNK_TOKEN, PAD_TOKEN] с помощью аргумента secials,\ncustom_vocab = build_vocab_from_iterator(yield_tokens(train_iter),\n                                         specials=[UNK_TOKEN, PAD_TOKEN])\n# причем специальном токену для out-of-vocabulary слов назначим\n# специальный индекс с помощью метода set_default_index\ncustom_vocab.set_default_index(custom_vocab[UNK_TOKEN])","metadata":{"id":"FNcEc-bVa_SK","execution":{"iopub.status.busy":"2023-09-28T14:08:13.492379Z","iopub.execute_input":"2023-09-28T14:08:13.493675Z","iopub.status.idle":"2023-09-28T14:08:19.987147Z","shell.execute_reply.started":"2023-09-28T14:08:13.493623Z","shell.execute_reply":"2023-09-28T14:08:19.986140Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"Давайте теперь сформируем пайплайны:\n\n    обработки текстов -- токенизируем и переводим в индексы словаря\n    обработки лейблов -- переводим строки neg и pos в бинарную разметку 0 и 1 соответственно.\n","metadata":{"id":"hAcG-tylbmBo"}},{"cell_type":"code","source":"# Пайплайн векторизации текста : разбиение текста на токены(последовательное применение\n# токенайзера) -- и словаря -- замены токенов\n# на индексы слов в словаре\n# максимальную длина текста MAX_LENGTH.\n# Создаем пайплайн как lambda-функцию-токенизирует входной текст с помощью tokenizer,\n# затем применяет custom_vocab к токенам,\n# а потом ограничивает длину листа индексированных токенов до MAX_LENGTH\n\nvocab_tokenizer_pipeline = lambda x: custom_vocab(tokenizer(x))[:MAX_LENGTH]","metadata":{"id":"1yvQe8ErbrMK","execution":{"iopub.status.busy":"2023-09-28T14:08:25.910549Z","iopub.execute_input":"2023-09-28T14:08:25.910925Z","iopub.status.idle":"2023-09-28T14:08:25.916480Z","shell.execute_reply.started":"2023-09-28T14:08:25.910893Z","shell.execute_reply":"2023-09-28T14:08:25.915154Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"# пайплайн векторизации меток классов представляет из себя индексирование\n# меток в словаре классов.\n# создадим пайплайн как lambda-функцию, которая применяет метод index\n# к словарю CLASSES и преобразует результат в int\n\nlabel_pipeline = lambda x: int(CLASSES.index(x))","metadata":{"id":"UV8CNsVwbq8T","execution":{"iopub.status.busy":"2023-09-28T14:08:32.132522Z","iopub.execute_input":"2023-09-28T14:08:32.132924Z","iopub.status.idle":"2023-09-28T14:08:32.138291Z","shell.execute_reply.started":"2023-09-28T14:08:32.132892Z","shell.execute_reply":"2023-09-28T14:08:32.137230Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"label_pipeline(1),label_pipeline(2)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cxu6g3VwrwfO","outputId":"786a0f50-1001-437c-e2c8-3a35c521790e","execution":{"iopub.status.busy":"2023-09-28T14:08:38.953705Z","iopub.execute_input":"2023-09-28T14:08:38.954064Z","iopub.status.idle":"2023-09-28T14:08:38.960374Z","shell.execute_reply.started":"2023-09-28T14:08:38.954036Z","shell.execute_reply":"2023-09-28T14:08:38.959289Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"(0, 1)"},"metadata":{}}]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FcMFmZ5adLCq","outputId":"d3a386b2-0c65-4f64-e859-6522ac896047","execution":{"iopub.status.busy":"2023-09-28T14:08:41.346683Z","iopub.execute_input":"2023-09-28T14:08:41.347043Z","iopub.status.idle":"2023-09-28T14:08:41.352117Z","shell.execute_reply.started":"2023-09-28T14:08:41.347015Z","shell.execute_reply":"2023-09-28T14:08:41.351244Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Создаем DataLoader (итерируемый объект, который содержит метки класса, токенизированные и проиндексированные в соответствии со словарем тексты и длины реплик. Одна итерация возвращает нам ровно BATCH_SIZE примеров), который будет подгружать в память токенизированные и переведенные в индексы тексты и целочисленные метки.","metadata":{"id":"DToDdVPwdblj"}},{"cell_type":"code","source":"def collate_batch(batch):\n    \"\"\"Функция collate_fn нужна DataLoader для того, чтоыб преобразовывать\n    получаемый на вход лист примеров (батч в виде листа исходных данных)\n    в мини-батч, представляющий из себя тензор.\n\n    Возвращает:\n    - label_list - метки классов в целочисленном виде, тензор на девайсе,\n    - text_list - токенизированные и проиндексированные тексты, тензор на девайсе,\n    - lengths - длины текстов в токенах, тензор на cpu\n                (используется nn.utils.rnn.pack_padded_sequence)\n    \"\"\"\n    label_list, text_list, lengths = [], [], []\n    for (_label, _text) in batch:\n        # добавим в список label_list преобразованный с помощью\n        # label_pipeline лейбл\n        label_list.append(label_pipeline(_label))\n        # добавим в список text_list преобразованный с помощью\n        # vocab_tokenizer_pipeline текст\n        text_list.append(vocab_tokenizer_pipeline(_text))\n        # добавим в список lengths длину токенизированного текста\n        lengths.append(torch.tensor(len(vocab_tokenizer_pipeline(_text)),\n                                    dtype=torch.int64))\n\n    # преобразуем label_list в torch.tensor с целочисленными значениями\n    label_list = torch.tensor(label_list, dtype=torch.int64)\n    # преобразуем lengths в torch.tensor с целочисленными значениями\n    lengths = torch.tensor(lengths, dtype=torch.int64)\n    # преобразуем text_list в тензор с помощью ToTensor,\n    # задав значение для padding-а custom_vocab[PAD_TOKEN],\n    # чтобы тексты были все единой длины - максимальной в батче.\n    # при этом помним, что в пайплайне мы уже ограничили максимальную длину\n    text_list = ToTensor(padding_value=custom_vocab[PAD_TOKEN]).forward(text_list)\n    return label_list.to(device), text_list.to(device), lengths\n\n\n# снова создадим итератор по обучающей выборке IMDB\ntrain_iter = IMDB(split='train')\n# Создадим DataLoader на основе train_iter,\n# задав BATCH_SIZE в качестве значения batch_size,\n# определим shuffle в значении False,\n# задав collate_batch в качестве collate_fn\ndataloader = DataLoader(train_iter,\n                        batch_size=BATCH_SIZE,\n                        shuffle=False,\n                        collate_fn=collate_batch)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T14:08:49.648410Z","iopub.execute_input":"2023-09-28T14:08:49.649129Z","iopub.status.idle":"2023-09-28T14:08:49.673126Z","shell.execute_reply.started":"2023-09-28T14:08:49.649094Z","shell.execute_reply":"2023-09-28T14:08:49.671980Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"for idx, (label, text, lengths) in enumerate(dataloader):\n    # метки класса -- это целочисленные индексы в списке классов\n    print(label)\n    # тексты -- это целочисленные индексы токенов текста в словаре токенов\n    print(text)\n    # длины -- это целочисленные длины в токенах каждого примера\n    # (не более `MAX_LENGTH`, так как мы ограничили максимальную длину еще\n    # в пайплайне обработки текстов)\n    print(lengths)\n\n    # все длины должны быть равны размеру батча\n    print(len(label))\n    print(len(text))\n    print(len(lengths))\n    break","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m8UaDdBsvJsv","outputId":"0e6cee2b-9e3b-43d5-d93f-28e034d9293a","execution":{"iopub.status.busy":"2023-09-28T14:08:57.184195Z","iopub.execute_input":"2023-09-28T14:08:57.184596Z","iopub.status.idle":"2023-09-28T14:08:57.443145Z","shell.execute_reply.started":"2023-09-28T14:08:57.184558Z","shell.execute_reply":"2023-09-28T14:08:57.441490Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\ntensor([[   13,  1568,    13,  ...,    12,   203,  2182],\n        [   13,   246,  1989,  ...,     4,    12,    69],\n        [   51,    70,     8,  ...,     1,     1,     1],\n        ...,\n        [   13,   482,    13,  ...,  5337, 75760,    18],\n        [   13,    97,     9,  ...,    44,    12,    64],\n        [   14,    21,    17,  ...,    21,     3,     3]], device='cuda:0')\ntensor([128, 128, 101, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n        128, 128,  92, 128,  99, 128, 128, 128, 128, 128, 121, 128, 128, 123,\n        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n        128, 128, 128,  57, 128, 128, 128, 128])\n64\n64\n64\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"id":"lfYsQP1Ymol-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Нейронная сеть\n\nСостоит из слоя перевода индексов токенов в плотные векторные представления Embedding, двунаправленной модели долгой краткосрочной памяти (Bidirectional Long Short-term Memory) и двух последовательных полносвязных слоев, размер выхода последнего равен числу классов, а размер предпоследнего представляет из себя гипер-параметр.\n\nСлой Embedding превращает проиндексированные токены в векторные представления токенов-плотную обучаемую матрицу, которая в данном случае инициализируется с помощью случайных чисел.","metadata":{"id":"Fj9LNa-fwL3j"}},{"cell_type":"code","source":"\nclass BiLSTMClassificationModel(nn.Module):\n\n    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes, pad_idx,\n                 bidirectional=True, dropout=0.1):\n        super().__init__()\n        # слой обучаемых векторных представлений nn.Embedding\n        # с заданным индексом паддинга pad_idx в качестве аргумента padding_idx,\n        # с заданным размером представлений embed_dim,\n        # с заданным размером словаря vocab_size и\n        # без изначальной инициализации\n        self.embedding = nn.Embedding(vocab_size, embed_dim,\n                                      padding_idx = pad_idx)\n        # слой nn.LSTM с заданным значением dropout, получающий на вход\n        # вектора размерности  embed_dim и возвращающий вектора\n        # скрытой размерности hidden_dim,\n        # также зададим bidirectional в качестве аргумента bidirectional\n        self.bilstm = nn.LSTM(embed_dim, hidden_dim,\n                              bidirectional=bidirectional,\n                              dropout=dropout, batch_first=True)\n        \n        # линейный слой nn.Linear,\n        # преобразующий вектора размерности hidden_dim * 2\n        # (так как используется bidirectional LSTM) в hidden_dim\n        self.fc1 = nn.Linear(hidden_dim * 2, hidden_dim)\n        # линейный слой nn.Linear,\n        #преобразующий вектора размерности hidden_dim * 2\n        # (так как используется bidirectional LSTM) в hidden_dim\n        self.fc2 = nn.Linear(hidden_dim , hidden_dim)\n        # линейный слой nn.Linear,\n        # преобразующий вектора размерности hidden_dim\n        # в размерность числа классов num_classes\n        self.fc3 = nn.Linear(hidden_dim, num_classes)\n        # слой nn.Dropout с заданной величиной dropout\n        #  для использования - он не имеет весов, поэтому можно\n        # задать один слой и использовать его в нескольких местах в сети\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, text, text_lengths):\n        # пропустим полученные на вход тексты через слой self.embedding\n        embedded = self.embedding(text)\n        # преобразуем векторные представления последовательностей\n        # с помощью специальной функции в формат, подходящий для LSTM\n        # https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pack_padded_sequence.html?highlight=pack_padded_sequence#torch.nn.utils.rnn.pack_padded_sequence\n        packed_embedded = nn.utils.rnn.pack_padded_sequence(\n            embedded, text_lengths, batch_first=True, enforce_sorted=False)\n        \n        # пропустим последовательность через нашу self.bilstm\n        packed_output, (hidden, cell) = self.bilstm(packed_embedded)\n        #second_bilstm, (hidden, cell) = self.bilstm(64)\n        # пропустим скрытые представлния через слой self.dropout\n        \n        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]),\n                                        dim = 1))\n        #packed_output, (hidden, cell) = self.bilstm(hidden)\n        \n        # пропустим полученные скрытые представления через слой self.fc1\n        output = self.fc1(hidden)\n        # пропустим полученные скрытые представления через слой self.fc2\n        \n        output = self.fc2(output)\n        # пропустим полученные скрытые представления через слой self.fc3\n       #output = self.dropout(output)\n        output = self.fc2(output)\n        output = self.fc2(output)\n        #output = self.dropout(output)\n        output = self.fc3(output)\n        # пропустим полученные скрытые представления через self.dropout\n        #output = self.dropout(output)\n        return output","metadata":{"id":"WzuuzlgvvuEK","execution":{"iopub.status.busy":"2023-09-28T18:18:21.557775Z","iopub.execute_input":"2023-09-28T18:18:21.558201Z","iopub.status.idle":"2023-09-28T18:18:21.586767Z","shell.execute_reply.started":"2023-09-28T18:18:21.558167Z","shell.execute_reply":"2023-09-28T18:18:21.585649Z"},"trusted":true},"execution_count":193,"outputs":[]},{"cell_type":"code","source":"train_iter = IMDB(split='train')\n\n\nnum_classes = len(CLASSES)\nvocab_size = custom_vocab.__len__()\n\n# инициализируем нашу модель BiLSTMClassificationModel,\n# передав необходимые параметры:\n# размер словаря,\n# размер векторных представлений,\n# размер скрытого пространства,\n# число классов,\n# индекс паддинга\n# параметр, будет ли модаль двунаправиленной,\n# значение дропаут,\n# а также перенесем нашу модель на девайс\nmodel = BiLSTMClassificationModel(\n    vocab_size,\n    embed_dim=64,\n    hidden_dim=128,\n    num_classes=num_classes,\n    pad_idx=custom_vocab[PAD_TOKEN],\n    bidirectional=True,\n    dropout=0.3\n).to(device)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oTX63w_8yQl6","outputId":"aa6c6b7a-d4c6-42cd-fc59-12679449f6f7","execution":{"iopub.status.busy":"2023-09-28T18:35:05.061503Z","iopub.execute_input":"2023-09-28T18:35:05.061888Z","iopub.status.idle":"2023-09-28T18:35:05.126414Z","shell.execute_reply.started":"2023-09-28T18:35:05.061859Z","shell.execute_reply":"2023-09-28T18:35:05.125437Z"},"trusted":true},"execution_count":202,"outputs":[]},{"cell_type":"code","source":"import time\n\n\ndef train(dataloader, epoch, optimizer, criterion):\n    # обязательно переводим модель в режим обучения с помощью метода train()\n    model.train()\n    total_acc, total_count = 0, 0\n    # интервал логгирования в числе батчей\n    log_interval = 100\n    start_time = time.time()\n\n    # итерируемся батчами по заданном даталоадеру\n    for idx, (label, text, lengths) in enumerate(dataloader):\n        # обнуляем градиенты с помощью метода zero_grad\n        optimizer.zero_grad()\n        # предсказываем распределение вероятностей по классам,\n        # передавай в модель text и lengths\n        predicted_label = model(text, lengths)\n        # подсчитываем лосс с помощью criterion,\n        # вычисляемого на основе predicted_label и label\n        loss = criterion(predicted_label, label)\n        # обратное распространение ошибки с помощью метода backward()\n        loss.backward()\n        # ограничиваем норму градиентов с помощью метода\n        # torch.nn.utils.clip_grad_norm_, в который передаются\n        # параметры модели model.parameters() и макс. значение нормы 0.1\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n        # делаем шаг оптимизатора, то есть обновляем веса модели,\n        # с помощью метода step()\n        optimizer.step()\n        # подсчитываем точность на батче\n        total_acc += (predicted_label.argmax(1) == label).sum().item()\n        # подсчитываем число примеров для усреднения точности\n        total_count += label.size(0)\n\n        if idx % log_interval == 0 and idx > 0:\n            # если пришло время -- логгируем\n            elapsed = time.time() - start_time\n            print('| epoch {:3d} | {:5d}/{:5d} batches '\n                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n                                              total_acc/total_count))\n            total_acc, total_count = 0, 0\n            start_time = time.time()\n\ndef evaluate(dataloader, criterion):\n    # обязательно переводим модель в режим инференса (эвалюации)\n    # с помощью метода eval()\n    model.eval()\n    total_acc, total_count = 0, 0\n\n    # эвалюация не должна обновлять градиенты модели\n    with torch.no_grad():\n      # итерируемся батчами по заданному даталоадеру\n        for idx, (label, text, lengths) in enumerate(dataloader):\n            # предсказываем распределение вероятностей по классам,\n            # передавай в модель text и lengths\n            predicted_label = model(text, lengths)\n             # подсчитываем лосс с помощью criterion,\n            # вычисляемого на основе predicted_label и label\n            loss = criterion(predicted_label, label)\n            # предсказываем метки классов и считаем точность\n            total_acc += (predicted_label.argmax(1) == label).sum().item()\n            # подсчитываем число примеров для усреднения точности\n            total_count += label.size(0)\n    return total_acc/total_count","metadata":{"id":"M0qHUtO_yTJw","execution":{"iopub.status.busy":"2023-09-28T16:54:01.035946Z","iopub.execute_input":"2023-09-28T16:54:01.036784Z","iopub.status.idle":"2023-09-28T16:54:01.050939Z","shell.execute_reply.started":"2023-09-28T16:54:01.036741Z","shell.execute_reply":"2023-09-28T16:54:01.049516Z"},"trusted":true},"execution_count":144,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data.dataset import random_split\nfrom torchtext.data.functional import to_map_style_dataset\n\n\ntrain_iter, test_iter = IMDB()\n\ntrain_dataset = to_map_style_dataset(train_iter)\ntest_dataset = to_map_style_dataset(test_iter)\n\n# определим число итоговых обучающих примеров\nnum_train = int(len(train_dataset) * 0.9)\n# получим индексы разбиения на тренировочную и валидационную подвыборки\n# с помощью функции random_split\nsplit_train_, split_valid_ = \\\n    random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n\n# создаем DataLoader для обучающей подвыборки\ntrain_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n                              shuffle=True, collate_fn=collate_batch)\n# создаем DataLoader для валидационной подвыборки\nvalid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n                              shuffle=True, collate_fn=collate_batch)\n# создаем DataLoader для тестовой подвыборки\ntest_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n                             shuffle=True, collate_fn=collate_batch)\n","metadata":{"id":"DGpymmdMzjgo","execution":{"iopub.status.busy":"2023-09-28T14:13:33.733862Z","iopub.execute_input":"2023-09-28T14:13:33.734227Z","iopub.status.idle":"2023-09-28T14:13:35.381904Z","shell.execute_reply.started":"2023-09-28T14:13:33.734195Z","shell.execute_reply":"2023-09-28T14:13:35.380911Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data.dataset import random_split\nfrom torchtext.data.functional import to_map_style_dataset\n# Hyperparameters\n\n\nEPOCHS = 10 # epoch\nLR = 5  # learning rate - lr\n\n# определим функцию потерь torch.nn.CrossEntropyLoss\ncriterion = torch.nn.CrossEntropyLoss()\n# определим оптимизатор torch.optim.SGD с заданным lr,\n# передав также параметры модели model.parameters()\noptimizer = torch.optim.SGD(model.parameters(), lr=LR)\n# определим расписание изменения значения lr torch.optim.lr_scheduler.StepLR\n# передав в качестве аргументов optimizer,\n# значение step_size равное 1, и значение gamma 0.1 (коэффициент убывания)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n\ntotal_accu = None\n\nvalid_accuracies = []\n\nfor epoch in range(1, EPOCHS + 1):\n    epoch_start_time = time.time()\n    # запускаем обучения на 1 эпоху с помощью нашей функции train\n    train(train_dataloader, epoch, optimizer, criterion)\n    # подсчитываем качество на валидационной подвыборке\n    # с помощью нашей функции evaluate\n    accu_val = evaluate(valid_dataloader, criterion)\n    valid_accuracies.append(accu_val)\n    if total_accu is not None and total_accu > accu_val:\n        scheduler.step()\n    else:\n        total_accu = accu_val\n    print('-' * 59)\n    print('| end of epoch {:3d} | time: {:5.2f}s | '\n          'valid accuracy {:8.3f} '.format(epoch,\n                                           time.time() - epoch_start_time,\n                                           accu_val))\n    print('-' * 59)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":525},"id":"PRQHBV_Hz2ry","outputId":"054bb3fc-df26-42dc-ec58-77b836afeb05","execution":{"iopub.status.busy":"2023-09-28T18:51:00.823597Z","iopub.execute_input":"2023-09-28T18:51:00.823970Z","iopub.status.idle":"2023-09-28T18:53:56.103397Z","shell.execute_reply.started":"2023-09-28T18:51:00.823941Z","shell.execute_reply":"2023-09-28T18:53:56.102333Z"},"trusted":true},"execution_count":209,"outputs":[{"name":"stdout","text":"| epoch   1 |   100/  352 batches | accuracy    0.787\n| epoch   1 |   200/  352 batches | accuracy    0.787\n| epoch   1 |   300/  352 batches | accuracy    0.784\n-----------------------------------------------------------\n| end of epoch   1 | time: 17.06s | valid accuracy    0.749 \n-----------------------------------------------------------\n| epoch   2 |   100/  352 batches | accuracy    0.813\n| epoch   2 |   200/  352 batches | accuracy    0.806\n| epoch   2 |   300/  352 batches | accuracy    0.794\n-----------------------------------------------------------\n| end of epoch   2 | time: 17.45s | valid accuracy    0.751 \n-----------------------------------------------------------\n| epoch   3 |   100/  352 batches | accuracy    0.823\n| epoch   3 |   200/  352 batches | accuracy    0.827\n| epoch   3 |   300/  352 batches | accuracy    0.827\n-----------------------------------------------------------\n| end of epoch   3 | time: 17.29s | valid accuracy    0.726 \n-----------------------------------------------------------\n| epoch   4 |   100/  352 batches | accuracy    0.880\n| epoch   4 |   200/  352 batches | accuracy    0.874\n| epoch   4 |   300/  352 batches | accuracy    0.888\n-----------------------------------------------------------\n| end of epoch   4 | time: 17.67s | valid accuracy    0.782 \n-----------------------------------------------------------\n| epoch   5 |   100/  352 batches | accuracy    0.890\n| epoch   5 |   200/  352 batches | accuracy    0.890\n| epoch   5 |   300/  352 batches | accuracy    0.892\n-----------------------------------------------------------\n| end of epoch   5 | time: 17.51s | valid accuracy    0.782 \n-----------------------------------------------------------\n| epoch   6 |   100/  352 batches | accuracy    0.900\n| epoch   6 |   200/  352 batches | accuracy    0.891\n| epoch   6 |   300/  352 batches | accuracy    0.900\n-----------------------------------------------------------\n| end of epoch   6 | time: 17.33s | valid accuracy    0.784 \n-----------------------------------------------------------\n| epoch   7 |   100/  352 batches | accuracy    0.907\n| epoch   7 |   200/  352 batches | accuracy    0.900\n| epoch   7 |   300/  352 batches | accuracy    0.900\n-----------------------------------------------------------\n| end of epoch   7 | time: 17.94s | valid accuracy    0.785 \n-----------------------------------------------------------\n| epoch   8 |   100/  352 batches | accuracy    0.912\n| epoch   8 |   200/  352 batches | accuracy    0.902\n| epoch   8 |   300/  352 batches | accuracy    0.903\n-----------------------------------------------------------\n| end of epoch   8 | time: 17.63s | valid accuracy    0.787 \n-----------------------------------------------------------\n| epoch   9 |   100/  352 batches | accuracy    0.910\n| epoch   9 |   200/  352 batches | accuracy    0.908\n| epoch   9 |   300/  352 batches | accuracy    0.909\n-----------------------------------------------------------\n| end of epoch   9 | time: 17.96s | valid accuracy    0.779 \n-----------------------------------------------------------\n| epoch  10 |   100/  352 batches | accuracy    0.918\n| epoch  10 |   200/  352 batches | accuracy    0.918\n| epoch  10 |   300/  352 batches | accuracy    0.915\n-----------------------------------------------------------\n| end of epoch  10 | time: 17.42s | valid accuracy    0.784 \n-----------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"print('Checking the results of train dataset.')\n# подсчитываем качество на обучающей подвыборке\n# с помощью нашей функции evaluate\naccu_train = evaluate(train_dataloader, criterion)\nprint('train accuracy {:8.3f}'.format(accu_train))","metadata":{"id":"0SU0Z8QB0JNf","execution":{"iopub.status.busy":"2023-09-28T18:54:02.307893Z","iopub.execute_input":"2023-09-28T18:54:02.308286Z","iopub.status.idle":"2023-09-28T18:54:15.188334Z","shell.execute_reply.started":"2023-09-28T18:54:02.308254Z","shell.execute_reply":"2023-09-28T18:54:15.187347Z"},"trusted":true},"execution_count":210,"outputs":[{"name":"stdout","text":"Checking the results of train dataset.\ntrain accuracy    0.929\n","output_type":"stream"}]},{"cell_type":"code","source":"print('Checking the results of test dataset.')\n# подсчитываем качество на тестовой подвыборке\n# с помощью нашей функции evaluate\naccu_test = evaluate(test_dataloader, criterion)\nprint('test accuracy {:8.3f}'.format(accu_test))","metadata":{"execution":{"iopub.status.busy":"2023-09-28T18:54:20.972496Z","iopub.execute_input":"2023-09-28T18:54:20.972875Z","iopub.status.idle":"2023-09-28T18:54:35.159817Z","shell.execute_reply.started":"2023-09-28T18:54:20.972845Z","shell.execute_reply":"2023-09-28T18:54:35.158962Z"},"trusted":true},"execution_count":211,"outputs":[{"name":"stdout","text":"Checking the results of test dataset.\ntest accuracy    0.778\n","output_type":"stream"}]}]}