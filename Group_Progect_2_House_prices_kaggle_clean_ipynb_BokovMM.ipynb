{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbYEJD9c8jsa",
        "outputId": "4409a80f-a1d2-4fc1-e99d-95d3a374ce96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.9/dist-packages (2.6.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (1.22.4)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (1.2.2)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (0.13.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (1.10.1)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (0.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.0.5->category_encoders) (2022.7.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->category_encoders) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.2.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.9/dist-packages (from statsmodels>=0.9.0->category_encoders) (23.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.9/dist-packages (1.7.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from xgboost) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from xgboost) (1.10.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install category_encoders\n",
        "!pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NalAF5KVnAkc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import timeit\n",
        "import xgboost as xgb\n",
        "\n",
        "from category_encoders import TargetEncoder\n",
        "from google.colab import files\n",
        "from lightgbm import LGBMRegressor\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, StackingRegressor, VotingRegressor\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.linear_model import LassoLarsCV, LinearRegression, ElasticNet#, SGDRegressor,LogisticRegression, LogisticRegressionCV,\n",
        "from sklearn.model_selection import train_test_split#, RandomizedSearchCV, cross_val_score\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, RobustScaler\n",
        "from sklearn.tree import DecisionTreeRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfG-BTGUnCwK"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('max_colwidth', 80)\n",
        "\n",
        "raw_df_train = pd.read_csv('https://raw.githubusercontent.com/Michael-Bokov/Sber_Data_Science/blob/main/train.csv', index_col=0)\n",
        "raw_df_test = pd.read_csv('https://raw.githubusercontent.com/Michael-Bokov/Sber_Data_Science/blob/main/test.csv', index_col=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEFjDBR9tPZm"
      },
      "source": [
        "#Work with categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7amMkDnnIM0"
      },
      "outputs": [],
      "source": [
        "def is_cat(df, col):\n",
        "  '''checks if a column is of object or category type'''\n",
        "  return df[col].dtype in ['object', 'category']\n",
        "\n",
        "def improve_cats(dataframe) -> pd.DataFrame:\n",
        "  '''turns dtypes 64->32 and object->category'''\n",
        "  df = dataframe.copy()\n",
        "  for col in df.columns:\n",
        "    if df[col].dtype == 'int64':\n",
        "      df[col] = df[col].astype('int32')\n",
        "    elif df[col].dtype == 'float64':\n",
        "      df[col] = df[col].astype('float32')\n",
        "    elif df[col].dtype == 'object':\n",
        "      df[col] = df[col].astype('category')\n",
        "    else:\n",
        "      print('Unknown data type')\n",
        "      return\n",
        "  return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYDBgi1jtefb"
      },
      "source": [
        "#Show statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TyxvPDhrYVV"
      },
      "outputs": [],
      "source": [
        "def adjusted_r2(yt,yp, colnum):\n",
        "  '''computes adjusted r2 score'''\n",
        "  return 1 - (1 - r2_score(yt, yp)) * ((yt.shape[0]-1) / (yt.shape[0] - colnum+(1e-12)))\n",
        "\n",
        "def print_scores(y_train, y_test, y_pred_train, y_pred_test, colnum):\n",
        "  '''outprints adjusted r2 and rmse results on train and validation'''\n",
        "  train_r2 =  adjusted_r2(y_train, y_pred_train, colnum)\n",
        "  test_r2 = adjusted_r2(y_test,y_pred_test, colnum)\n",
        "  train_rmse = np.sqrt(mean_squared_error(np.log(y_pred_train), np.log(y_train)))\n",
        "  test_rmse = np.sqrt(mean_squared_error(np.log(y_pred_test), np.log(y_test)))\n",
        "  text = f'train r2: {train_r2}\\ntrain rmse: {train_rmse}\\n\\ntest r2: {test_r2}\\ntest rmse: {test_rmse}\\n'\n",
        "  print(text)\n",
        "  return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mtt5HUcs0Dho"
      },
      "source": [
        "#Split dataframe to X,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNwAn6fRnXVV"
      },
      "outputs": [],
      "source": [
        "def split_data(df, target):\n",
        "  '''splits data'''\n",
        "  X = df.drop(target, axis=1)\n",
        "  y = df[target]\n",
        "  return train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwaDXaLitT8f"
      },
      "source": [
        "#Work with model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTLLd3oLohzm"
      },
      "outputs": [],
      "source": [
        "def train_model(X_train, y_train):\n",
        "  '''subj'''\n",
        "  estimators = [('LinReg',LinearRegression()), ('Lasso',LassoLarsCV(max_iter=15,eps=0.01)),\n",
        "                ('Tree',DecisionTreeRegressor(max_depth=5)), ('LGBR', LGBMRegressor(max_depth = 5, learning_rate = 0.05)),\n",
        "                ('Elastic',ElasticNet(alpha=0.0005,random_state=42))]\n",
        "  pipe = make_pipeline(RobustScaler(), StackingRegressor(estimators=estimators, final_estimator = RandomForestRegressor(max_depth=6)))\n",
        "  pipe.fit(X_train, y_train)\n",
        "  y3_train = np.exp((np.log(y_train) + np.log(pipe.predict(X_train))) / 2)\n",
        "  pipe.fit(X_train, y3_train)\n",
        "\n",
        "\n",
        "\n",
        "  return pipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_8lSGYAOLuQ"
      },
      "outputs": [],
      "source": [
        "def train_model2(X_train, y_train):\n",
        "  estimators = [('LinReg',LinearRegression()), ('Lasso',LassoLarsCV(max_iter=15,eps=0.01)), ('Tree',DecisionTreeRegressor(max_depth=5))]\n",
        "\n",
        "  pipe1 = make_pipeline(RobustScaler(), xgb.XGBRegressor(colsample_bytree=0.4,\n",
        "                             gamma=0.045,\n",
        "                             learning_rate=0.05,\n",
        "                             max_depth=10,\n",
        "                             min_child_weight=1.5,\n",
        "                             n_estimators=300,\n",
        "                             reg_alpha=0.65,\n",
        "                             reg_lambda=0.45,\n",
        "                             subsample=0.95))\n",
        "  pipe2 = make_pipeline(RobustScaler(), LassoLarsCV(max_iter=15,eps=0.01))\n",
        "  pipe3 = make_pipeline(RobustScaler(), DecisionTreeRegressor(max_depth=5))\n",
        "  estimators = [('LinReg',LinearRegression()), ('Lasso',LassoLarsCV(max_iter=15,eps=0.01)),\n",
        "                ('Tree',DecisionTreeRegressor(max_depth=5)), ('LGBR', LGBMRegressor(max_depth = 5, learning_rate = 0.05)),\n",
        "                ('Elastic',ElasticNet(alpha=0.0005,random_state=42))]\n",
        "  pipe = make_pipeline(RobustScaler(), StackingRegressor(estimators=estimators, final_estimator = RandomForestRegressor(max_depth=6)))\n",
        "\n",
        "  blend = VotingRegressor(estimators=[('pipe1', pipe1), ('pipe2', pipe2), ('pipe3', pipe3), ('pipe4',pipe)], weights=[0.2, 0.1, 0.1, 0.6])\n",
        "\n",
        "\n",
        "  blend.fit(X_train, y_train)\n",
        "  y3_train = np.exp((np.log(y_train) + np.log(blend.predict(X_train))) / 2)\n",
        "  blend.fit(X_train, y3_train)\n",
        "\n",
        "  return blend\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvsPPHWZnXv2"
      },
      "outputs": [],
      "source": [
        "def split_run_test(df, target = 'SalePrice'):\n",
        "  '''splits data and runs model'''\n",
        "  X_train, X_test, y_train, y_test = split_data(df, target)\n",
        "  model = train_model2(X_train, y_train)\n",
        "\n",
        "  y_pred_train = model.predict(X_train)\n",
        "  y_pred_test = model.predict(X_test)\n",
        "  txt = print_scores(y_train, y_test, y_pred_train, y_pred_test, len(X_train.columns))\n",
        "  return model, txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "5RQ20Ng-n9of",
        "outputId": "3b868975-87eb-4dac-8358-692c380306c6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"def get_shap(X_train, X_test, model):\\n  explainer = shap.Explainer(model.predict, X_train)\\n  shap_values = explainer(X_test)\\n  shap.plots.waterfall(shap_values[0])\\n\\ndef grid(X_train, y_train):\\n  estimators = [('LinReg',LinearRegression()), \\n                ('Lasso',LassoLarsCV(max_iter=15,eps=0.01)), \\n                ('Tree',DecisionTreeRegressor(max_depth=5)), \\n                ('LGBR', LGBMRegressor(max_depth=5, learning_rate=0.05)),\\n                ('Elastic',ElasticNet(alpha=0.0005,random_state=42))]\\n                \\n  pipe = make_pipeline(RobustScaler(), \\n                      StackingRegressor(estimators=estimators, \\n                                        final_estimator=RandomForestRegressor(max_depth=6)))\\n\\n  param_grid = {\\n      'stackingregressor__final_estimator__n_estimators': [10, 50, 100],\\n      'stackingregressor__final_estimator__max_depth': [3, 5, 7],\\n      'stackingregressor__final_estimator__min_samples_split': [2, 4, 8],\\n      'stackingregressor__Elastic__l1_ratio': [0.1, 0.5, 0.9],      \\n  }\\n\\n  grid = GridSearchCV(pipe, param_grid=param_grid, cv=5)\\n  grid.fit(X_train, y_train)\\n  print('grid best params: ', grid.best_params_)\\n  print('grid best score: ', grid.best_score_)\""
            ]
          },
          "execution_count": 806,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def get_permutations(df):\n",
        "  '''Pick best columns'''\n",
        "  X_train, X_test, y_train, y_test = split_data(df, 'SalePrice')\n",
        "  model = train_model2(X_train, y_train)\n",
        "  result = permutation_importance(model, X_train, y_train, n_repeats=10, random_state=42)\n",
        "  importance_dict = dict(zip(X_train.columns, result.importances_mean))\n",
        "  sorted_importance = sorted(importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
        "  print(sorted_importance)\n",
        "  #get_shap(X_train, X_test, model)\n",
        "  #grid(X_train, y_train)\n",
        "  return [x[0] for x in sorted_importance]\n",
        "\n",
        "'''def get_shap(X_train, X_test, model):\n",
        "  explainer = shap.Explainer(model.predict, X_train)\n",
        "  shap_values = explainer(X_test)\n",
        "  shap.plots.waterfall(shap_values[0])\n",
        "\n",
        "def grid(X_train, y_train):\n",
        "  estimators = [('LinReg',LinearRegression()),\n",
        "                ('Lasso',LassoLarsCV(max_iter=15,eps=0.01)),\n",
        "                ('Tree',DecisionTreeRegressor(max_depth=5)),\n",
        "                ('LGBR', LGBMRegressor(max_depth=5, learning_rate=0.05)),\n",
        "                ('Elastic',ElasticNet(alpha=0.0005,random_state=42))]\n",
        "\n",
        "  pipe = make_pipeline(RobustScaler(),\n",
        "                      StackingRegressor(estimators=estimators,\n",
        "                                        final_estimator=RandomForestRegressor(max_depth=6)))\n",
        "\n",
        "  param_grid = {\n",
        "      'stackingregressor__final_estimator__n_estimators': [10, 50, 100],\n",
        "      'stackingregressor__final_estimator__max_depth': [3, 5, 7],\n",
        "      'stackingregressor__final_estimator__min_samples_split': [2, 4, 8],\n",
        "      'stackingregressor__Elastic__l1_ratio': [0.1, 0.5, 0.9],\n",
        "  }\n",
        "\n",
        "  grid = GridSearchCV(pipe, param_grid=param_grid, cv=5)\n",
        "  grid.fit(X_train, y_train)\n",
        "  print('grid best params: ', grid.best_params_)\n",
        "  print('grid best score: ', grid.best_score_)'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GQpobcjtntq"
      },
      "source": [
        "#Work with columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eW_Mbnfqttti"
      },
      "outputs": [],
      "source": [
        "def create_cols(df):\n",
        "  #create Total SF\n",
        "  df[\"TotalSF\"] = df[\"1stFlrSF\"] + df[\"2ndFlrSF\"] + df[\"TotalBsmtSF\"]+df['LotArea']\n",
        "  #create Porch\n",
        "  df['PorchSF'] = df['OpenPorchSF'] + df['EnclosedPorch'] + df['3SsnPorch'] + df['ScreenPorch']\n",
        "  #Create green area\n",
        "  df[\"OutsideArea\"] = df[\"LotArea\"] - df[\"GrLivArea\"] - df[\"GarageArea\"]\n",
        "  #Create month sold * year\n",
        "  df['MonthSold'] = df['YrSold']*12 + df['MoSold'] #-df['YrSold'].min()\n",
        "  #dates_frames  = ['YearBuilt', 'YearRemodAdd', 'GarageYrBlt', 'YrSold','MoSold']\n",
        "  #Create booleans\n",
        "  df['Has2Floors'] = df['2ndFlrSF'].apply(lambda x: 1 if x>0 else 0)\n",
        "  df['Has1Floors'] = df['1stFlrSF'].apply(lambda x: 1 if x>0 else 0)\n",
        "  df['HasPorch'] = df['PorchSF'].apply(lambda x: 1 if x>0 else 0)\n",
        "  df['HasWood'] = df['WoodDeckSF'].apply(lambda x: 1 if x>0 else 0)\n",
        "  df['HasFireplace'] = df['Fireplaces'].apply(lambda x: 1 if x>0 else 0)\n",
        "  #create bath\n",
        "  fullbsmtb = df['BsmtFullBath'].apply(lambda x: x if x > 0 else 0)\n",
        "  halfbsmtb = df['BsmtHalfBath'].apply(lambda x: x*0.5 if x > 0 else 0)\n",
        "  fullb = df['FullBath'].apply(lambda x: x if x > 0 else 0)\n",
        "  halfb = df['HalfBath'].apply(lambda x: x*0.5 if x > 0 else 0)\n",
        "  df['Bath'] = fullbsmtb + halfbsmtb + fullb + halfb\n",
        "  return df\n",
        "\n",
        "def log_cols(df, log_cols):\n",
        "  '''adds 1 to all numeric columns and np.logs handpicked columns'''\n",
        "  for column in [col for col in df.columns if not is_cat(df, col)]:\n",
        "    df[column] = df[column]+1\n",
        "  for col in log_cols:\n",
        "    df[col] = np.log(df[col])\n",
        "  return df\n",
        "\n",
        "def plotme(df, cols):\n",
        "  for col in cols:\n",
        "    if col != 'SalePrice':\n",
        "      sns.scatterplot(y = df['SalePrice'], x = df[col])\n",
        "\n",
        "def categorize_cols(df):\n",
        "  \"\"\"fill NaNs\"\"\"\n",
        "  for col in df.columns:\n",
        "    if df[col].isna().any():\n",
        "      if is_cat(df, col):\n",
        "        df[col] = df[col].cat.add_categories(['MISSING'])\n",
        "        df[col] = df[col].fillna('MISSING')\n",
        "        df[col] = df[col].cat.remove_unused_categories()\n",
        "      else:\n",
        "        if col not in ['GarageArea', 'KitchenAbvGr', 'TotRmsAbvGrd', 'LotArea',\\\n",
        "                       'TotalBsmtSF', 'BedroomAbvGr', 'Fireplaces', 'LotFrontage', \\\n",
        "                       'WoodDeckSF', 'MasVnrArea', '2ndFlrSF','GarageArea', 'WoodDeckSF',\\\n",
        "                       'BsmtFinSF1', 'BsmtFinSF2','BsmtUnfSF', 'LowQualFinSF', '1stFlrSF']:\n",
        "          df[col] = df[col].fillna(df[col].mean())\n",
        "        else:\n",
        "          df[col] = df[col].fillna(0)\n",
        "  return df\n",
        "\n",
        "\"\"\"def encode_cols(df, cols):\n",
        "  '''Use Label encoder'''\n",
        "  for col in cols:\n",
        "    encoder = LabelEncoder()\n",
        "    df[col+'_e'] = encoder.fit_transform(df[col])\n",
        "  return df\"\"\"\n",
        "\n",
        "def drop_categories(df):\n",
        "  '''drop cat values'''\n",
        "  cats = [col for col in df.columns if is_cat(df, col)]\n",
        "  return df.drop(columns = cats)\n",
        "\n",
        "def iqr(df, columns, mult=3):\n",
        "  '''cut outliers'''\n",
        "  df = df.copy()\n",
        "  for col in columns:\n",
        "    d=df[col].describe()\n",
        "    val =(d['50%'] + (d['75%']-d['25%'])) * mult\n",
        "    df = df[df[col] <= val]\n",
        "  return df\n",
        "\n",
        "def work_df(df, to_log = ['LotFrontage', 'LotArea', 'GrLivArea', 'GarageArea'], target =[], to_drop = []):\n",
        "  df = df.copy()\n",
        "  df = improve_cats(df)\n",
        "  df = create_cols(df)\n",
        "  df = df.drop(columns = to_drop)\n",
        "  df = categorize_cols(df)\n",
        "\n",
        "  df['OutsideArea'] = df['OutsideArea'].apply(lambda x: x if x>0 else 0)\n",
        "\n",
        "  df = log_cols(df, target+to_log)\n",
        "  return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghzYg92OyjZo"
      },
      "source": [
        "#Creating variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKJ7DCGf1Qv9"
      },
      "outputs": [],
      "source": [
        "cols_to_log = ['LotFrontage', 'LotArea', 'GrLivArea','TotalSF','OutsideArea',\n",
        "               'MonthSold', 'TotalBsmtSF', 'YrSold', 'YearBuilt','YearRemodAdd',\n",
        "               'GarageYrBlt', '2ndFlrSF','GarageArea', 'WoodDeckSF', 'BsmtFinSF1',\n",
        "               'BsmtFinSF2','BsmtUnfSF', 'LowQualFinSF', '1stFlrSF']\n",
        "\n",
        "cols_to_iqr = ['SalePrice','LotFrontage', 'LotArea', 'MasVnrArea', 'TotalBsmtSF',\n",
        "               'GrLivArea', 'BedroomAbvGr', 'KitchenAbvGr', 'Fireplaces',\n",
        "               'GarageArea', 'PorchSF', 'OutsideArea', 'TotalSF', '2ndFlrSF', '1stFlrSF']\n",
        "\n",
        "cols_to_drop = ['OpenPorchSF','EnclosedPorch', '3SsnPorch', 'ScreenPorch',\n",
        "                'PoolArea', 'MiscVal', 'GarageCars', 'BsmtFullBath', 'BsmtHalfBath',\n",
        "                'FullBath', 'HalfBath']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hB_o1wi2t7HD"
      },
      "outputs": [],
      "source": [
        "df = work_df(raw_df_train, to_log = cols_to_log, to_drop = cols_to_drop, target = ['SalePrice'])\n",
        "df_test = work_df(raw_df_test, to_log = cols_to_log, to_drop = cols_to_drop)\n",
        "\n",
        "df = iqr(df, cols_to_iqr)\n",
        "\n",
        "cols = ['Neighborhood']#, 'LotShape']#, 'FireplaceQu']\n",
        "for col in cols:\n",
        "  encoder = TargetEncoder(cols = col)\n",
        "  df[col+'_te'] = encoder.fit_transform(df[col], df['SalePrice'])\n",
        "  df_test[col+'_te'] = encoder.transform(df_test[col])\n",
        "\n",
        "df = drop_categories(df)\n",
        "df_test = drop_categories(df_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGfpw7jkEJuC"
      },
      "source": [
        "#Getting best columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nl4XMqje1yoU",
        "outputId": "390d7ba2-a538-4da6-b339-25b3d46cabda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('MonthSold', 0.2559863085101183), ('MoSold', 0.23088428628186336), ('YrSold', 0.2102053476054362), ('OverallQual', 0.17855402935447007), ('GrLivArea', 0.13369949603953984), ('Neighborhood_te', 0.0816968371576701), ('Has2Floors', 0.042743246712187065), ('TotalSF', 0.041153367508094806), ('2ndFlrSF', 0.039778165011898695), ('YearBuilt', 0.02652715509832848), ('OverallCond', 0.025114403839854416), ('Bath', 0.02389970850142048), ('1stFlrSF', 0.0200721810723009), ('BsmtFinSF1', 0.012399168041773479), ('TotalBsmtSF', 0.011893362412140052), ('GarageArea', 0.01162788615021696), ('LotArea', 0.010280523048528223), ('YearRemodAdd', 0.009124523526379213), ('WoodDeckSF', 0.005614155837502155), ('PorchSF', 0.004838893914205833), ('Fireplaces', 0.003910936393791753), ('GarageYrBlt', 0.0025357128390656293), ('MSSubClass', 0.001980483197334404), ('BedroomAbvGr', 0.001625011773261542), ('OutsideArea', 0.0015274198232802737), ('HasWood', 0.001153836437764022), ('KitchenAbvGr', 0.0009467576900471398), ('BsmtUnfSF', 0.0008724151201446207), ('HasFireplace', 0.000545791025921083), ('BsmtFinSF2', 0.0005306382692087496), ('LotFrontage', 0.0004732180348218096), ('HasPorch', 0.0004541883909500499), ('TotRmsAbvGrd', 0.00024208746392796466), ('MasVnrArea', 0.00013651371573791815), ('LowQualFinSF', 2.7707915335661858e-05), ('Has1Floors', 0.0)]\n"
          ]
        }
      ],
      "source": [
        "#to_drop = []#'Modern', 'HasBsmt', 'HasGarage', 'HasPool','HasVnr']\n",
        "df1 = df.copy()           #.drop(columns = to_drop)\n",
        "df_test1 = df_test.copy() #.drop(columns = to_drop)\n",
        "columns = get_permutations(df1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3S1puB0tEnw4",
        "outputId": "3593e93f-ca56-4808-fa62-306622acafef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train r2: 0.9201655824226073\n",
            "train rmse: 0.008856756000216827\n",
            "\n",
            "test r2: 0.8852497170287503\n",
            "test rmse: 0.010478333335842714\n",
            "\n"
          ]
        }
      ],
      "source": [
        "cols = ['SalePrice']+columns\n",
        "model, txt = split_run_test(df1[cols])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYee6lwHtp36"
      },
      "outputs": [],
      "source": [
        "y_pred_test = model.predict(df_test[columns])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGIVRYNAGjyH",
        "outputId": "5a6f884a-2f47-4c50-d7c7-2ac597b64354"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('OverallQual', 0.21633836129820394), ('MonthSold', 0.1802484789017727), ('YrSold', 0.15529974524957618), ('MoSold', 0.15275694648356444), ('GrLivArea', 0.09752758306380607), ('Neighborhood_te', 0.06139514137178821), ('Bath', 0.03186661237343259), ('1stFlrSF', 0.025320247987242184), ('TotalSF', 0.022142236283274976), ('2ndFlrSF', 0.019286759690202927), ('Has2Floors', 0.018583098079942562), ('YearBuilt', 0.017806293419251475), ('OverallCond', 0.015841797850137885), ('TotalBsmtSF', 0.011485639396208946), ('GarageArea', 0.011443266486685765), ('YearRemodAdd', 0.00967645738591626), ('BsmtFinSF1', 0.008357597623870849), ('PorchSF', 0.002710187819691778), ('WoodDeckSF', 0.002709309013777317), ('Fireplaces', 0.002490679527070383), ('TotRmsAbvGrd', 0.0016940670890067343), ('BedroomAbvGr', 0.0013833940152164436), ('MSSubClass', 0.0011952509256802247), ('HasFireplace', 0.0011559039031330044), ('BsmtUnfSF', 0.0010451099946064968), ('KitchenAbvGr', 0.000744599438558402), ('LotArea', 0.0007413526271735527), ('OutsideArea', 0.0007357852682319365), ('HasPorch', 0.0006732586966241682), ('GarageYrBlt', 0.0006665115895556518), ('LotFrontage', 0.00036418909784472484), ('HasWood', 0.00023764789790524653), ('BsmtFinSF2', 0.0001334842298439165), ('LowQualFinSF', 6.783544814206177e-05), ('MasVnrArea', 3.2319849668893673e-06), ('Has1Floors', 0.0)]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "df_test_result = df_test.copy()\n",
        "df_test_result['SalePrice'] = y_pred_test\n",
        "#pd.concat([df_test[columns], pd.DataFrame({'SalePrice':y_pred_test})], axis=1)\n",
        "new_df = pd.concat([df1, df_test_result.sample(frac=0.6, random_state=42)])\n",
        "new_df = new_df.dropna()\n",
        "new_df.reset_index(drop=True)\n",
        "columns = get_permutations(new_df)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFAbM8UvH8XC",
        "outputId": "ff4f6ffe-0e02-408c-e28f-16ac1f09c24f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train r2: 0.9457550549961163\n",
            "train rmse: 0.0072676115466568155\n",
            "\n",
            "test r2: 0.9214724849541059\n",
            "test rmse: 0.008654206641508967\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model, txt = split_run_test(new_df[['SalePrice']+columns])\n",
        "y_pred_test = model.predict(df_test[columns])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqaxaphTP3Zy",
        "outputId": "ede6ea5b-531f-4f0d-a9d1-649f9fc67a5a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1459, 36)"
            ]
          },
          "execution_count": 815,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "-ns9cnabty53",
        "outputId": "0d800204-6780-4e1e-acc1-9cbe36d11ea3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5e3131c8-3110-41f6-a39b-2abca6d7bf5b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1461</td>\n",
              "      <td>122360.735480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1462</td>\n",
              "      <td>155519.882292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1463</td>\n",
              "      <td>175415.946335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1464</td>\n",
              "      <td>183187.224109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1465</td>\n",
              "      <td>194958.470326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1454</th>\n",
              "      <td>2915</td>\n",
              "      <td>85673.636691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1455</th>\n",
              "      <td>2916</td>\n",
              "      <td>91683.421150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1456</th>\n",
              "      <td>2917</td>\n",
              "      <td>162971.177882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1457</th>\n",
              "      <td>2918</td>\n",
              "      <td>121881.759491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1458</th>\n",
              "      <td>2919</td>\n",
              "      <td>198475.750229</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1459 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e3131c8-3110-41f6-a39b-2abca6d7bf5b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5e3131c8-3110-41f6-a39b-2abca6d7bf5b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5e3131c8-3110-41f6-a39b-2abca6d7bf5b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        Id      SalePrice\n",
              "0     1461  122360.735480\n",
              "1     1462  155519.882292\n",
              "2     1463  175415.946335\n",
              "3     1464  183187.224109\n",
              "4     1465  194958.470326\n",
              "...    ...            ...\n",
              "1454  2915   85673.636691\n",
              "1455  2916   91683.421150\n",
              "1456  2917  162971.177882\n",
              "1457  2918  121881.759491\n",
              "1458  2919  198475.750229\n",
              "\n",
              "[1459 rows x 2 columns]"
            ]
          },
          "execution_count": 835,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ids = np.arange(1461, 2920)\n",
        "my_result = pd.DataFrame({'Id': ids, 'SalePrice': np.e**y_pred_test})\n",
        "my_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "0MfNRB6_uoZ4",
        "outputId": "5ddc337e-2d00-453e-cc91-5414330423e7"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_50408ecd-8e2a-43a6-9b4f-bc657e79049b\", \"submission.csv\", 34486)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "my_result.to_csv('submission.csv', index=False)\n",
        "files.download('submission.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiFKDV0Axlwz"
      },
      "source": [
        "#Work with FTP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WV6eliNIxlct"
      },
      "outputs": [],
      "source": [
        "def connect(address='0.0.0.0', name = 'anonymous', pas = ''):\n",
        "\tftp = ftplib.FTP(address)\n",
        "\tftp.login(name, pas)\n",
        "\treturn ftp\n",
        "\n",
        "def ret(ftp, filename = 'test.csv'):\n",
        "\tfile = io.BytesIO()\n",
        "\tftp.retrbinary('RETR '+filename, file.write)\n",
        "\tfile.seek(0)\n",
        "\tdf = pd.read_csv(file)\n",
        "\treturn df\n",
        "\n",
        "def write(df, ftp, filename = 'test.csv'):\n",
        "  file = io.BytesIO()\n",
        "  df.to_csv(file, index = False)\n",
        "  data = file.getvalue()\n",
        "  ftp.storbinary('STOR '+filename, io.BytesIO(data))\n",
        "  ftp.quit()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
