{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"    !pip install wandb","metadata":{"execution":{"iopub.status.busy":"2023-06-06T23:10:02.485825Z","iopub.execute_input":"2023-06-06T23:10:02.486182Z","iopub.status.idle":"2023-06-06T23:10:14.632852Z","shell.execute_reply.started":"2023-06-06T23:10:02.486153Z","shell.execute_reply":"2023-06-06T23:10:14.631768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Аннотация. В данном ноутбуке реализована сегментация изображений нервных клеток из Kaggle Sartorius - Cell Instance Segmentation.\n# В отличае от оригинального соревнования также дополнительно добавлено предсказание типа(класса) клеток.\n# Архитектура модифицированный Unet (c измененной функцией активации, добавлением Dropout и Linear слоев для класификации клеток UnetWithCellType (20 эпох)). Логирование wandb(закомментировано).Формирование submisson.csv соревнования и отрисовка результатов в произвольных цветах. \n# Также реализована вторая модель с transfer learning UnetWithResNet (resnet101). Так как предобученные 3х канальные(RGB) модели обучены на цветных картинках, то в случаях картинок градации серого они, в целом, справляются так же как специально обученные на градациях серого модели, но за большее число эпох(40 эпох). UNetWithResNet замораживает базовую модель ResNet101 и модифицирует ее слои для обработки монохромных данных, после этого происходит дообучение модели на монохромных изображениях с использованием модифицированных слоев и дополнительных слоев. \n# Боков Михаил Михайлович\n\nTrain Loss ~ 0.18-0.2, Valid Loss: 0.13-0.15,Accuracy_Score: 92-96%, Cell Type Accuracy: 95-98%,Precision:75-77% IOU:~0.5-0.6, F1(Dice) ~0.7-0.8 (в зависимотсти от learning rate, momentum и расположения dropout слоев)\n\n# bokov.mike@gmail.com\n","metadata":{}},{"cell_type":"code","source":"import os\nos.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\"\nimport wandb # для Логирования\nimport gc\nimport cv2,PIL # работа с изображениями\nimport pandas as  pd\nimport numpy as np\nimport random\nfrom pathlib import Path\nimport time # Для времени обучения\nfrom tqdm import * #Для бар'а прохождения эпохи\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim # для оптимизаторов\nfrom torchvision import datasets # для данных\nimport torchvision.models as models # для предобученной модели ResNet\nimport torchvision.transforms as transforms\n\nimport albumentations as A #Агументации\nfrom albumentations.pytorch import ToTensorV2\nfrom torch.utils.data import Dataset # Для создания трансформированного train датасета\nfrom sklearn.metrics import accuracy_score,f1_score #Метрика\n\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2023-06-17T23:53:12.382690Z","iopub.execute_input":"2023-06-17T23:53:12.383183Z","iopub.status.idle":"2023-06-17T23:53:18.664384Z","shell.execute_reply.started":"2023-06-17T23:53:12.383146Z","shell.execute_reply":"2023-06-17T23:53:18.663384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Зафиксируем seed для воспроизводимости\n\ndef seed_everything(seed):\n    random.seed(seed) # фиксируем генератор случайных чисел\n    os.environ['PYTHONHASHSEED'] = str(seed) # фиксируем заполнения хешей\n    np.random.seed(seed) # фиксируем генератор случайных чисел numpy\n    torch.manual_seed(seed) # фиксируем генератор случайных чисел pytorch\n    torch.cuda.manual_seed(seed) # фиксируем генератор случайных чисел для GPU\n    torch.backends.cudnn.deterministic = True # выбираем только детерминированные алгоритмы (для сверток)\n    torch.backends.cudnn.benchmark = False # фиксируем алгоритм вычисления сверток","metadata":{"execution":{"iopub.status.busy":"2023-06-17T23:53:21.834295Z","iopub.execute_input":"2023-06-17T23:53:21.834645Z","iopub.status.idle":"2023-06-17T23:53:21.841832Z","shell.execute_reply.started":"2023-06-17T23:53:21.834615Z","shell.execute_reply":"2023-06-17T23:53:21.840646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n\n# Задаем Конфигурацию\n\n    api = \"\"# вписать свой API Wandb  \n    project = \"Cells-Segmentation\"# \n    entity = \"michaelbokov\"# ввести свой логин\n    num_epochs = 19 # количество эпох\n    train_batch_size = 8 # размер батча обучающей выборки\n    test_batch_size = 512 # размер батча тестовой выборки\n    num_workers = 2 # количество активных процессов на загрузку данных\n    lr = 0.00875 # learning_rate\n    seed = 2022 # для функции воспроизводимости\n\n    wandb = True # флаг использования Wandb\n    TRAIN_CSV = '../input/sartorius-cell-instance-segmentation/train.csv'\n    TRAIN_DIR = '../input/sartorius-cell-instance-segmentation/train/'\n    TEST_DIR = '../input/sartorius-cell-instance-segmentation/test/'\n    MOMENTUM = 0.850\n\n    WEIGHT_DECAY = 0.0001 ","metadata":{"execution":{"iopub.status.busy":"2023-06-18T03:55:21.964571Z","iopub.execute_input":"2023-06-18T03:55:21.964944Z","iopub.status.idle":"2023-06-18T03:55:21.971641Z","shell.execute_reply.started":"2023-06-18T03:55:21.964912Z","shell.execute_reply":"2023-06-18T03:55:21.970629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def CFG2dict(f):\n    return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))","metadata":{"execution":{"iopub.status.busy":"2023-06-17T23:53:30.872324Z","iopub.execute_input":"2023-06-17T23:53:30.872668Z","iopub.status.idle":"2023-06-17T23:53:30.878101Z","shell.execute_reply.started":"2023-06-17T23:53:30.872640Z","shell.execute_reply":"2023-06-17T23:53:30.876965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(CFG2dict(CFG))","metadata":{"execution":{"iopub.status.busy":"2023-06-17T23:53:33.119523Z","iopub.execute_input":"2023-06-17T23:53:33.119926Z","iopub.status.idle":"2023-06-17T23:53:33.126716Z","shell.execute_reply.started":"2023-06-17T23:53:33.119896Z","shell.execute_reply":"2023-06-17T23:53:33.124843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **EDA**","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(CFG.TRAIN_CSV,sep=',')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-17T23:53:36.423796Z","iopub.execute_input":"2023-06-17T23:53:36.424866Z","iopub.status.idle":"2023-06-17T23:53:36.989614Z","shell.execute_reply.started":"2023-06-17T23:53:36.424824Z","shell.execute_reply":"2023-06-17T23:53:36.988701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n\n#\nimg_names = Path(CFG.TRAIN_DIR).glob('*')\npbar = tqdm(img_names, total=df.id.unique().shape[0])\nfor img_name in pbar:\n    img = cv2.imread(img_name.as_posix())\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    hist = cv2.calcHist([img], [0], None, [256], [0, 256])\n    axs[0].plot(hist)\n# График распределения классов клеток\ncell_class = df['cell_type'].value_counts()\naxs[1].bar(cell_class.index, cell_class.values)\naxs[0].set_title('Гистограмма цветов изображений.')\naxs[1].set_title('Распределение типов клеток.')\n# Уменьшение размеров графиков\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-17T23:53:39.110670Z","iopub.execute_input":"2023-06-17T23:53:39.111421Z","iopub.status.idle":"2023-06-17T23:53:50.227506Z","shell.execute_reply.started":"2023-06-17T23:53:39.111385Z","shell.execute_reply":"2023-06-17T23:53:50.226644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Таким образом видно что по цветам выбросов нет, то есть нет порченных, неполных изображений, \"битых пикселей\". Так же виден сильный дисбаланс в классах. Закодируем классы.**","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(CFG.TRAIN_CSV,sep=',')\nCell_type_encoding={'shsy5y':0,\"astro\":1,\"cort\":2}\ndf['cell_type']=df['cell_type'].map(Cell_type_encoding)\ndf['cell_type'] = df['cell_type'].astype(int)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-17T23:53:52.504257Z","iopub.execute_input":"2023-06-17T23:53:52.504602Z","iopub.status.idle":"2023-06-17T23:53:52.881928Z","shell.execute_reply.started":"2023-06-17T23:53:52.504572Z","shell.execute_reply":"2023-06-17T23:53:52.880941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Аннотации (annotations) представляют собой информацию о масках каждой отдельной клетки на изображении закодированных методом RLE. Маска обычно представлена в виде сегментов, где каждый сегмент представляет одну клетку. У некоторых изображений маска разделена на много частей в строках датасета.**\n\n**RLE (Run-Length Encoding) представляет собой способ кодирования маски, где последовательность значений используется для описания длины подряд идущих пикселей.В данном случае пары чисел(начальной позиции пикселя и количества).**\n","metadata":{}},{"cell_type":"code","source":"def rle_decode(mask_rle, shape):\n    '''\n    Функция принимает RLE-кодированную маску и размеры исходного изображения, и возвращает декодированную бинарную маску (массив NumPy).\n    mask_rle: RLE-кодированная маска в виде строки\n    shape : размеры исходного изображения передается как пара (высота, ширина).\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape)","metadata":{"execution":{"iopub.status.busy":"2023-06-17T23:53:56.145813Z","iopub.execute_input":"2023-06-17T23:53:56.147088Z","iopub.status.idle":"2023-06-17T23:53:56.159980Z","shell.execute_reply.started":"2023-06-17T23:53:56.147051Z","shell.execute_reply":"2023-06-17T23:53:56.158714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Функция для произвольного задания цветов маски по каналам RGB**","metadata":{}},{"cell_type":"code","source":"def create_mask_image(binary_mask):\n    '''\n    Создание маски изображения в произвольных цветах (трансформация пары 0,1 по каналам в настраиваемые цвета)\n    binary_mask: бинарная маска (массив NumPy)\n    '''\n    mask_image = np.zeros((binary_mask.shape[0], binary_mask.shape[1], 3), dtype=np.uint8)\n    mask_image[..., 0] = binary_mask * 222  # Красный канал\n    mask_image[..., 1] = binary_mask * 155  # Зеленый канал\n    mask_image[..., 2] = binary_mask * 100  # Синий канал\n    mask_image[np.where(binary_mask == 0)] = [0, 125, 255] \n    return mask_image","metadata":{"execution":{"iopub.status.busy":"2023-06-17T23:54:29.889150Z","iopub.execute_input":"2023-06-17T23:54:29.889501Z","iopub.status.idle":"2023-06-17T23:54:29.895810Z","shell.execute_reply.started":"2023-06-17T23:54:29.889474Z","shell.execute_reply":"2023-06-17T23:54:29.894816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def draw_trio (img_id):\n    '''\n    Отрисовка оригинального изображения, маски и наложения в ряд.\n    '''\n   \n   \n    plt.figure(figsize=(18, 6))\n    plt.subplot(1, 3, 1)\n    plt.imshow(cv2.imread(CFG.TRAIN_DIR + img_id + '.png'))\n    plt.axis(\"off\")\n    plt.title(f'Оригинал Изображения: {img_id}')\n\n   \n    plt.subplot(1, 3, 2)\n    mask_rle = df[df.id == img_id]['annotation'].str.cat(sep=' ')\n    mask = create_mask_image(rle_decode(mask_rle,(520, 704)))\n    \n    plt.imshow(mask)\n    plt.axis(\"off\")\n    plt.title(f'Маска Изображения: {img_id}')\n    \n    plt.subplot(1, 3, 3)\n    plt.imshow(cv2.imread(CFG.TRAIN_DIR + img_id + '.png'))\n    plt.imshow(mask, alpha=0.2)\n    plt.axis(\"off\")\n    plt.title(f'Наложение: {img_id}')\n\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-17T23:54:01.722935Z","iopub.execute_input":"2023-06-17T23:54:01.723627Z","iopub.status.idle":"2023-06-17T23:54:01.732420Z","shell.execute_reply.started":"2023-06-17T23:54:01.723593Z","shell.execute_reply":"2023-06-17T23:54:01.731210Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Сгруппируем исходный датасет по названиям изображений.","metadata":{}},{"cell_type":"code","source":"df_g = df.copy()\ndf_g['annotation'] = 1\ndf_g = df_g.groupby(['id', 'width', 'height', 'cell_type']).count().reset_index()\ndf_groupby = df_g[['id','annotation', 'width', 'height', 'cell_type']]\ndf_groupby.head()\n","metadata":{"execution":{"iopub.status.busy":"2023-06-17T23:54:22.287427Z","iopub.execute_input":"2023-06-17T23:54:22.287802Z","iopub.status.idle":"2023-06-17T23:54:22.403834Z","shell.execute_reply.started":"2023-06-17T23:54:22.287746Z","shell.execute_reply":"2023-06-17T23:54:22.402951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**При каждом запуске открисуем, что бы не повторяться, произвольные 3 тройки клеток (исходное изображение, заданная маска,наложение).**","metadata":{}},{"cell_type":"code","source":"def get_random_id_by_type(df, type_value):\n    '''\n    Функция берет произвольный id картинки по переданному типу клетки\n    '''\n    group = df[df['cell_type'] == type_value]\n    random_id = group['id'].sample(n=1).values[0]\n    return random_id","metadata":{"execution":{"iopub.status.busy":"2023-06-17T23:54:15.272454Z","iopub.execute_input":"2023-06-17T23:54:15.272829Z","iopub.status.idle":"2023-06-17T23:54:15.278306Z","shell.execute_reply.started":"2023-06-17T23:54:15.272796Z","shell.execute_reply":"2023-06-17T23:54:15.277380Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Отрисовка**","metadata":{}},{"cell_type":"code","source":"cell_types_unique=df_groupby['cell_type'].unique()#.astype(str)\nfor cell_t in cell_types_unique:\n    img_id=get_random_id_by_type(df,cell_t)\n    draw_trio(img_id)","metadata":{"execution":{"iopub.status.busy":"2023-06-17T23:54:33.070787Z","iopub.execute_input":"2023-06-17T23:54:33.071133Z","iopub.status.idle":"2023-06-17T23:54:35.666579Z","shell.execute_reply.started":"2023-06-17T23:54:33.071103Z","shell.execute_reply":"2023-06-17T23:54:35.665704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Preprocessing**","metadata":{}},{"cell_type":"markdown","source":"**Классы функций.\n*1) Класс трансформаций(агументаций). Происходят трансформации(изменение размеров, отображение,транспонирование) train части, однако для корректной оценки модели, для valid части также нужно произвести изменение размеров изображений.\\\n**2) Класс для создания тренировочных и валидационных датасетов на основе изображений для передачи в PyTorch Dataloader. Содержит изображение, маску, код типа клетки.\\**\n**3) Класс модернизированной архитектуры UNet.**","metadata":{}},{"cell_type":"code","source":"class DataTransforms:\n    '''\n    Класс агументаций\n    '''\n    @staticmethod\n    def transform_train():\n        transforms = [\n            A.Resize(256, 256, p=1),  # Изменение размера\n            A.HorizontalFlip(p=0.5),  # Отображение\n            A.Transpose(p=0.5),       # Транспонирование  \n            A.Rotate(limit=45, p=0.5),# Повороты на угол до 45 градусов\n            ToTensorV2(p=1)\n        ]\n        return A.Compose(transforms)\n\n    @staticmethod\n    def transform_valid():\n        transforms = [\n            A.Resize(256, 256, p=1),\n            ToTensorV2(p=1)\n        ]\n        return A.Compose(transforms)","metadata":{"execution":{"iopub.status.busy":"2023-06-17T23:54:44.973806Z","iopub.execute_input":"2023-06-17T23:54:44.974159Z","iopub.status.idle":"2023-06-17T23:54:44.981539Z","shell.execute_reply.started":"2023-06-17T23:54:44.974131Z","shell.execute_reply":"2023-06-17T23:54:44.980436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CellDataset(Dataset):\n    def __init__(self, ids, df, image_dir, transforms=None, status='train',resnet=False):\n        super().__init__()\n        self.ids = ids\n        self.df = df\n        self.image_dir = image_dir\n        self.transforms = transforms\n        self.status = status\n        self.resnet = resnet\n\n    def __len__(self):\n        return len(self.ids)\n\n    def __getitem__(self, index):\n        img_id = self.ids[index]\n\n        # Загрузка изображения\n        img_path = os.path.join(self.image_dir, img_id + \".png\")\n        img_bgr = cv2.imread(img_path) #читаем в numpay массив BGR\n        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB) # -> RGB\n        img = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY) # -> В оттенки серого, уменьшая число каналов с 3 до 1 и нормализуем\n        if self.resnet==False:\n            img = np.array(img).astype(np.float32)\n            img /= 255.0\n            \n        else:\n            img_rgb = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n            img = np.array(img_rgb).astype(np.float32)\n            img /= 255.0 \n            mean = np.array([0.485, 0.456, 0.406])\n            std = np.array([0.229, 0.224, 0.225])\n            img -= mean  # Вычитание среднего значения\n            img /= std  # Деление на стандартное отклонение\n       \n        if self.status == 'train':  # При обучении возвращает набор (изображение,маска,идентификатор-название изображения,тип клетов)\n            # Загрузка маски\n            mask_rle = self.df[self.df[\"id\"] == img_id]['annotation'].str.cat(sep=' ')\n            mask = rle_decode(mask_rle, (520, 704)) # Декодирование маски \n            mask = np.array(mask).astype(np.float32)\n\n            # Загрузка типа клетки (0,1,2)\n            cell_type = self.df[self.df[\"id\"] == img_id][\"cell_type\"].values[0]\n\n            # Применение агументаций\n            if self.transforms is not None:\n                augmented = self.transforms(image=img, mask=mask)\n                img = augmented[\"image\"]\n                mask = augmented[\"mask\"]\n                \n            return img, mask,img_id,cell_type\n        else:\n            if self.transforms is not None:\n                img = self.transforms(image=img)[\"image\"]\n            return img, img_id","metadata":{"execution":{"iopub.status.busy":"2023-06-17T23:54:51.399279Z","iopub.execute_input":"2023-06-17T23:54:51.399626Z","iopub.status.idle":"2023-06-17T23:54:51.413812Z","shell.execute_reply.started":"2023-06-17T23:54:51.399598Z","shell.execute_reply":"2023-06-17T23:54:51.412889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Архитектура U-Net состоит из энкодера (downsampling path) и декодера (upsampling path). Они объединяются в единую модель, где происходит передача информации между ними. \n\nЭнкодер (Downsampling Path): Этот слой отвечает за постепенное уменьшение размера изображения и извлечение признаков более высокого уровня. Он состоит из повторяющихся блоков, включающих сверточные слои, функции активации и операцию пулинга. Каждый блок уменьшает размер изображения и увеличивает количество признаков.\n\nДекодер (Upsampling Path): Этот слой отвечает за восстановление пространственного разрешения изображения и восстановление деталей. Он состоит из повторяющихся блоков, включающих операцию транспонированной свертки (например, ConvTranspose2d), сверточные слои, функции активации и операции объединения (например, конкатенация). Каждый блок увеличивает размер изображения и уменьшает количество признаков, используя информацию из энкодера. Поэтому в декодере обычно выполняется конкатенация или объединение данных из соответствующих слоев энкодера и текущего слоя декодера.\n\nОбычно в UNet используются слои  функции активации (ReLU), операций пулинга (MaxPooling),транспонированной свертки (ConvTranspose2d).\n\nВ данной архитектуре заменена функция активации (SELU), добавлены промежуточные сверточные слои,линейные слои, и слои дропаута.**\n\n","metadata":{}},{"cell_type":"code","source":"class ConvBlock(nn.Module):\n    '''\n    Сверточные слои c батч-нормализацией и активацией\n    '''\n    def __init__(self, in_channels, out_channels):\n        super(ConvBlock, self).__init__()\n\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.activation1 = nn.SELU()\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.activation2 = nn.SELU()\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.activation1(x)\n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.activation2(x)\n        return x\nclass EncoderBlock_main(nn.Module):\n    ''''\n    Энкодер\n    1) Пулинг\n    2) Свертка\n    3) Батч-нормализация\n    4) Активация\n    '''\n    def __init__(self, in_channels, out_channels):\n        super(EncoderBlock_main, self).__init__()\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.activation1 = nn.SELU()\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.activation2 = nn.SELU()\n\n    def forward(self, x):\n        x = self.pool(x)\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.activation1(x)\n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.activation2(x)\n        return x\n\nclass CellTypeEncoder(nn.Module):\n    '''\n    Линейные слои для определения типа клетки\n    '''\n    def __init__(self, in_features, num_classes,dropout=True):\n        super(CellTypeEncoder, self).__init__()\n\n        hidden_size1 = 512\n        hidden_size2 = 256\n        hidden_size3 = 128\n        hidden_size4 = 64\n        \n        self.fc1 = nn.Linear(in_features, hidden_size1)\n        #self.dropout1 = nn.Dropout(p=0.2) \n        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n        #self.dropout1 = nn.Dropout(p=0.2) \n        self.fc3 = nn.Linear(hidden_size2, hidden_size3)\n        self.dropout1 = nn.Dropout(p=0.2) \n        self.fc4 = nn.Linear(hidden_size3, hidden_size4)\n        self.fc5 = nn.Linear(hidden_size4, num_classes)\n        self.selu = nn.SELU()\n    def forward(self, x):\n        x = self.selu(self.fc1(x))\n        #x = self.dropout1(x)\n        x = self.selu(self.fc2(x))\n        x = self.dropout1(x)\n        x = self.selu(self.fc3(x))\n        #x = self.dropout1(x)\n        x = self.selu(self.fc4(x))\n        #x = self.dropout1(x)\n        x = self.fc5(x)\n        return x\n\nclass UNetWithCellType(nn.Module):\n    '''\n    1)Входные слои сверток с нормализацией и активацией\n    2)Слои сверток, Пулинга, Дропаутов\n    3)Слои транспонированной свертки и последующие сверточные слои с нормализацией и активациями\n    4)Линейные слои для определения типа клеток\n    5)Выходные слои отдельно для масок и вероятностей типов клетки\n    '''\n    def __init__(self, in_channels=1, out_channels=1, num_classes=3, encoder_cell_features=1024,dropout=True):\n        super(UNetWithCellType, self).__init__()\n        self.encoder1 = ConvBlock(in_channels,64)\n        #self.dropout1 = nn.Dropout(p=0.2)\n        self.encoder2 = EncoderBlock_main(64, 128)\n        #self.dropout1 = nn.Dropout(p=0.2)\n        self.encoder3 = EncoderBlock_main(128, 256)\n        self.encoder4 = EncoderBlock_main(256, 512)\n        #self.dropout2 = nn.Dropout(p=0.2)\n        self.encoder5 = EncoderBlock_main(512, 1024)\n        self.dropout2 = nn.Dropout(p=0.2)\n        self.decoder4 = nn.ConvTranspose2d(\n            in_channels=1024, out_channels=512,\n            kernel_size=2, stride=2)\n        self.decoder4_1 = ConvBlock(1024, 512)\n        #self.dropout3 = nn.Dropout(p=0.2)\n        self.decoder3 = nn.ConvTranspose2d(\n            in_channels=512, out_channels=256,\n            kernel_size=2, stride=2)\n        self.decoder3_1 = ConvBlock(512, 256)\n        #self.dropout3 = nn.Dropout(p=0.2)\n        self.decoder2 = nn.ConvTranspose2d(\n            in_channels=256, out_channels=128,\n            kernel_size=2, stride=2)\n        \n        self.decoder2_1 = ConvBlock(256, 128)\n        self.decoder1 = nn.ConvTranspose2d(\n            in_channels=128, out_channels=64,\n            kernel_size=2, stride=2)\n        \n        self.decoder1_1 = ConvBlock(128, 64)\n        self.dropout3 = nn.Dropout(p=0.2)\n        self.mask_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n        self.cell_type_encoder = CellTypeEncoder(encoder_cell_features, num_classes,dropout=True)\n        self.sigmoid = nn.Sigmoid()\n        self.softmax = nn.Softmax(dim=1)\n\n    def forward(self, x):\n        enc1 = self.encoder1(x)\n        #enc1 = self.dropout1(enc1)\n        enc2 = self.encoder2(enc1)\n        #enc2 = self.dropout2(enc2)\n        enc3 = self.encoder3(enc2)\n        enc4 = self.encoder4(enc3)\n        #enc4 = self.dropout2(enc4)\n        enc5 = self.encoder5(enc4)\n        enc5 = self.dropout2(enc5)\n        dec4 = self.decoder4(enc5)\n        dec4_1 = self.decoder4_1(torch.cat([enc4, dec4], 1))\n        #dec4_1 = self.dropout2(dec4_1)\n        dec3 = self.decoder3(dec4_1)\n        dec3_1 = self.decoder3_1(torch.cat([enc3, dec3], 1))\n        #dec3_1 = self.dropout3(dec3_1)\n        dec2 = self.decoder2(dec3_1)\n        dec2_1 = self.decoder2_1(torch.cat([enc2, dec2], 1))\n        dec1 = self.decoder1(dec2_1)\n        #dec1 = self.dropout3(dec1)\n        dec1_1 = self.decoder1_1(torch.cat([enc1, dec1], 1))\n        dec1_1 = self.dropout3(dec1_1)\n        mask_output = self.mask_conv(dec1_1)\n        cell_type_features = torch.mean(enc5, dim=(2, 3))  # Извлечение признаков для классификации типов клеток\n        cell_type_output = self.cell_type_encoder(cell_type_features)\n        mask_output = self.sigmoid(mask_output)\n        cell_type_output = self.softmax(cell_type_output)\n        return mask_output, cell_type_output","metadata":{"execution":{"iopub.status.busy":"2023-06-18T04:12:13.858086Z","iopub.execute_input":"2023-06-18T04:12:13.858436Z","iopub.status.idle":"2023-06-18T04:12:13.888339Z","shell.execute_reply.started":"2023-06-18T04:12:13.858408Z","shell.execute_reply":"2023-06-18T04:12:13.887288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Подготовка обучения. Создание train и valid загрузчиков.**\n","metadata":{}},{"cell_type":"code","source":"def train_and_valid_dataloaders(df, train_ids, val_ids,resnet=False):\n    '''\n    Создание тренировочных и валидационых PyTorch загрузчиков пакетов данных.\n    '''\n    trn = df_groupby[df_groupby['id'].isin(train_ids)].reset_index(drop=True)\n    val = df_groupby[df_groupby['id'].isin(val_ids)].reset_index(drop=True)\n    \n    \n    train_dataset = CellDataset(trn[\"id\"].to_numpy(),df,CFG.TRAIN_DIR,transforms=DataTransforms.transform_train(),resnet=resnet)\n    valid_dataset = CellDataset(val[\"id\"].to_numpy(),df,CFG.TRAIN_DIR,transforms=DataTransforms.transform_valid(),resnet=resnet)\n  \n    \n    train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=CFG.train_batch_size,num_workers=CFG.num_workers,shuffle=True)\n    valid_loader = torch.utils.data.DataLoader(valid_dataset,batch_size=CFG.train_batch_size,num_workers=CFG.num_workers,shuffle=False)\n           \n    return train_loader, valid_loader\n","metadata":{"execution":{"iopub.status.busy":"2023-06-17T23:55:18.697618Z","iopub.execute_input":"2023-06-17T23:55:18.698730Z","iopub.status.idle":"2023-06-17T23:55:18.707089Z","shell.execute_reply.started":"2023-06-17T23:55:18.698689Z","shell.execute_reply":"2023-06-17T23:55:18.705786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def iou_calc(predicted_mask, true_mask):\n    predicted_mask = predicted_mask.cpu().numpy()\n    true_mask = true_mask.cpu().numpy()\n    intersection = np.logical_and(predicted_mask, true_mask)\n    union = np.logical_or(predicted_mask, true_mask)\n    iou_score = np.sum(intersection) / np.sum(union)\n    return iou_score","metadata":{"execution":{"iopub.status.busy":"2023-06-17T23:55:20.992254Z","iopub.execute_input":"2023-06-17T23:55:20.992602Z","iopub.status.idle":"2023-06-17T23:55:20.999098Z","shell.execute_reply.started":"2023-06-17T23:55:20.992573Z","shell.execute_reply":"2023-06-17T23:55:20.998066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def precisionscore(true_masks, predicted_masks):\n    true_positives = 0\n    false_positives = 0\n    \n    for true, pred in zip(true_masks, predicted_masks):\n        if pred == 1 and true == 1:\n            true_positives += 1\n        elif pred == 1 and true == 0:\n            false_positives += 1\n    \n    if true_positives + false_positives > 0:\n        precision_score = true_positives / (true_positives + false_positives)\n    else:\n        precision_score = 0.0\n    \n    return precision_score\n","metadata":{"execution":{"iopub.status.busy":"2023-06-17T23:55:22.695259Z","iopub.execute_input":"2023-06-17T23:55:22.695614Z","iopub.status.idle":"2023-06-17T23:55:22.701807Z","shell.execute_reply.started":"2023-06-17T23:55:22.695583Z","shell.execute_reply":"2023-06-17T23:55:22.700896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nДля подсчета точности мы также используем бинарные предсказанные сегменты predicted_segments,сравнивая их с истинными масками masks.\nЗатем мы вычисляем общее количество пикселей total и количество правильно предсказанных пикселей correct, чтобы вычислить точность.\nИли мы создаем два списка predicted_masks и true_masks, в которые добавляем предсказанные и истинные маски соответственно. \nЗатем мы используем accuracy_score(true_masks, predicted_masks) для вычисления точности и умножаем результат на 100 для получения \nпроцентного значения.\n","metadata":{}},{"cell_type":"code","source":"def train(model,train_loader, valid_loader, num_epochs, lr):#,wandb=True):\n    #wandb.login(key=CFG.api)\n    os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\"\n    os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n    #if CFG.wandb:\n        #os.environ[\"WANDB_API_KEY\"] = \"\"#CFG.api\n        #wandb.login(key=CFG.api)#wandb_api)\n     #   wandb.init(project=CFG.project, entity=CFG.entity, reinit=True,config=CFG2dict(CFG))\n      #  wandb.watch(model, log='all')\n    seed= seed_everything(CFG.seed)\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model.to(device)\n   # print(model)\n    criterion_cell_type = nn.CrossEntropyLoss().to(device)\n    criterion = nn.BCELoss().to(device)  # Бинарная кросс-энтропия\n    optimizer = torch.optim.SGD(model.parameters(), weight_decay=CFG.WEIGHT_DECAY, lr = lr, momentum=CFG.MOMENTUM)\n    #if CFG.wandb:\n     #   wandb.watch(model, log='all') # логируем все (метрики, лоссы, градиенты)\n      # For Visualization\n    train_loss_list = []\n    valid_loss_list = []\n    cell_type_accuracy_list=[]\n    iou_scores_list = []\n    f1_scores_list = []\n   \n    for epoch in tqdm(range(num_epochs), desc=\"Epochs\"):\n        start_time = time.time() \n        model.train()  # Устанавливаем модель в режим обучения\n        train_loss = 0.0\n        total_iou = 0.0\n        total_f1 = 0.0\n        num_samples = 0\n        for images, masks,i,cell_type in train_loader:\n            images = images.to(device).float()\n            masks = masks.to(device).float()\n            cell_type = cell_type.to(device)\n            masks = masks.view(images.shape[0], -1, 256, 256)\n           \n            optimizer.zero_grad()\n            # Прямой проход\n            outputs, predicted_cell_type = model(images) \n            loss_mask = criterion(outputs, masks) #Лосс масок\n            loss_cell_type=criterion_cell_type(predicted_cell_type,cell_type) #Лосс типов клеток\n            # Обратный проход\n            loss=0.9*loss_mask+0.1*loss_cell_type  # Лосс модели с весами по функциям потерь масок и типов клеток\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item() * images.size(0)\n        train_loss /= len(train_loader.dataset)\n        # Валидация\n        model.eval()  # Устанавливаем модель в режим оценки \n        valid_loss = 0.0\n        correct = 0\n        total = 0\n        predicted_masks = []\n        predicted_cell_types = []\n        true_masks = []\n        true_cell_types = []\n        #correct_cell_types = 0\n        #total_cell_types = 0\n        with torch.no_grad():\n            for images, masks,i,cell_type in valid_loader:\n                images, masks = images.to(device).float(),masks.to(device).float()\n                cell_type = cell_type.to(device).float() \n                                               \n                outputs, predicted_cell_type = model(images) # Предсказанные маски(вероятностные значения для каждого пикселя или пиксельного канала.)\n                                                             #и типы клеток(тензоры)\n                               \n                masks = masks.view(images.shape[0], -1, 256, 256)\n                loss = criterion(outputs, masks)\n                valid_loss += loss.item() * images.size(0)\n                     \n                predicted_segments = (outputs > 0.5).float() #Преобразования предсказанных сегментов (outputs) в бинарные значения 0 и 1. \n                                                            #Пороговое значение 0.5.  Пиксель фон(0), объект (1).\n                iou = iou_calc(predicted_segments, masks)  \n                f1 = f1_score(predicted_segments.view(-1).cpu().numpy(), masks.view(-1).cpu().numpy())\n                total_iou += iou * images.size(0)\n                total_f1 += f1 * images.size(0)\n                num_samples += images.size(0)\n                                \n                predicted_masks.extend(predicted_segments.view(-1).tolist())# Список предсказанных масок\n                true_masks.extend(masks.view(-1).tolist()) # Список известных масок\n                predicted_cell = torch.max(predicted_cell_type, dim=1) # Так как три класса клеток, то для каждого image из батча выбор максимальной вероятности(класса).\n                \n                predicted_cell_types.extend(predicted_cell)  # Список предсказанных cell_type\n                true_cell_types.extend(cell_type.view(-1).tolist())  # Список истинных значения cell_type\n             \n                accuracy = (predicted_segments == masks).float().mean() * 100 #Ручной расчет точности\n                total += masks.view(-1).size(0) #Ручной расчет точности.Увеличение переменной total на количество образцов в текущем батче. Что бы получить итоговое количество наборов \n                correct += (predicted_segments == masks).sum().item() #Ручной расчет точности.\n               \n            valid_loss /= len(valid_loader.dataset)\n            \n            accuracy = correct / total * 100 # Ручной расчет Accuracy\n            accuracyscore = accuracy_score(true_masks, predicted_masks) * 100\n                  \n            #correct_cell_types = 0\n            #total_cell_types = 0\n            predicted_cell_types = [tensor.tolist() for tensor in predicted_cell_types] # Список вероятностных тензоров в список\n            result_ = []\n            result_ = [sublist for sublist in predicted_cell_types[1::2]]  # Вырезаем вероятности и оставляем подсписки номеров классов\n            result = [item for sublist in result_ for item in sublist] # Убираем подсписки в один список предсказанных классов\n            predicted_cell_types=result\n            predicted_cell_types = np.array(predicted_cell_types)\n           \n            cell_type_accuracy = accuracy_score(true_cell_types, predicted_cell_types) * 100 #Поэлементное вычисление точности совпадения 2х списков\n            \n            precision=precisionscore(true_masks, predicted_masks)*100\n            #-классов поступивших изображений и предсказанных классов\n            epoch_f1 = total_f1 / num_samples\n            epoch_iou = total_iou / num_samples \n            iou_scores_list.append(epoch_iou)\n            f1_scores_list.append(epoch_f1)\n        \n        end_time = time.time()  # Записываем время окончания эпохи\n        epoch_time = end_time - start_time  # Вычисляем время прохождения эпохи\n     \n        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Valid Loss: {valid_loss:.4f}, Accuracy_Manualy: {accuracy:.2f}%,Accuracy_Score: {accuracyscore:.2f}%,Cell Type Accuracy: {cell_type_accuracy:.2f}%,IoU: {epoch_iou:.2f},Precision:{precision:.2f},F1: {epoch_f1:.2f},Time: {epoch_time:.2f} seconds\")\n        train_loss_list.append(train_loss)\n        valid_loss_list.append(valid_loss)\n        cell_type_accuracy_list.append(cell_type_accuracy/100)\n        #f1_scores_list.append(f1)\n   \n        #del model, optimizer, train_loader, valid_loader, train_losses, valid_losses\n        #if wandb:\n        #    wandb.log({'Train_loss': train_loss,\n         #              'Valid Loss': valid_loss,\n         #              'Accuracy': accuracyScore,\n         #              'Precision': precision})\n   # gc.collect()\n    #wandb.finish()\n    plt.plot(range(1, num_epochs+1), train_loss_list,c='blue', label='Train Loss')\n    plt.plot(range(1, num_epochs+1), valid_loss_list,c='cyan', label='Valid Loss')\n    plt.plot(range(1, num_epochs+1), cell_type_accuracy_list,c='green', label='Cell type accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss/Accuracy')\n    plt.legend()\n    plt.show()\n    gc.collect()\n    torch.cuda.empty_cache()\n    \n    print(f\" Summary Train Loss: {train_loss:.4f}, Valid Loss: {valid_loss:.4f},Accuracy_Score: {accuracyscore:.2f}%,Cell Type Accuracy: {cell_type_accuracy:.2f}%,Precision:{precision:.2f},IoU: {epoch_iou:.2f},F1: {epoch_f1:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2023-06-17T23:55:25.810546Z","iopub.execute_input":"2023-06-17T23:55:25.810943Z","iopub.status.idle":"2023-06-17T23:55:25.839196Z","shell.execute_reply.started":"2023-06-17T23:55:25.810911Z","shell.execute_reply":"2023-06-17T23:55:25.838205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Обучение**","metadata":{}},{"cell_type":"code","source":"#wandb.login(key=\")\nos.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\"\nos.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n# Создание датасета и загрузчиков\nids = df['id'].unique()\nfrom sklearn.model_selection import train_test_split\ntrain_ids, val_ids = train_test_split(ids, test_size=0.2, random_state=CFG.seed)\ntrain_loader, valid_loader = train_and_valid_dataloaders(df, train_ids, val_ids,resnet=False)\n\n# Создание модели и обучение\nmodel = UNetWithCellType(dropout=True)\n#modelRN = UNetWithResNet()\ntrain(model,train_loader, valid_loader, CFG.num_epochs, CFG.lr)#,wandb=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Сохраним модель**","metadata":{}},{"cell_type":"code","source":"model_name = f\"model_{CFG.num_epochs}_{CFG.train_batch_size}_{CFG.lr}_{CFG.MOMENTUM}_{CFG.WEIGHT_DECAY}.pth\"\ntorch.save(model.state_dict(), model_name)","metadata":{"execution":{"iopub.status.busy":"2023-06-18T01:43:45.805573Z","iopub.execute_input":"2023-06-18T01:43:45.806298Z","iopub.status.idle":"2023-06-18T01:43:46.030607Z","shell.execute_reply.started":"2023-06-18T01:43:45.806260Z","shell.execute_reply":"2023-06-18T01:43:46.029596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Создание, сохранение submission.csv и отрисовка предскзаний.**\n","metadata":{}},{"cell_type":"code","source":"def mask_to_rle(mask):\n    '''\n    Функция преобразует бинарную маску в RLE-формат.\n    '''\n    mask_cpu = mask.cpu()  # Копирование тензора на CPU\n    pixels = mask_cpu.T.flatten()  # Преобразование маски в одномерный массив\n    pixels = np.concatenate([[0], pixels, [0]])  # Добавление фиктивных значений 0 в начало и конец массива\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1  # Определение индексов изменения значений\n    runs[1::2] -= runs[:-1:2]  # Вычисление длины повторяющихся сегментов\n    rle = ' '.join(str(x) for x in runs)  # Преобразование массива длин сегментов в строку\n    return rle","metadata":{"execution":{"iopub.status.busy":"2023-06-18T01:43:49.442592Z","iopub.execute_input":"2023-06-18T01:43:49.442974Z","iopub.status.idle":"2023-06-18T01:43:49.450370Z","shell.execute_reply.started":"2023-06-18T01:43:49.442944Z","shell.execute_reply":"2023-06-18T01:43:49.449320Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Создание тестового датасета и загрузчиков\n\nfiles = os.listdir(CFG.TEST_DIR)\nimage_ids = np.array([os.path.splitext(file)[0] for file in files])\nids = []\nrle_test_preds = []\noriginal_size = (704, 520)  \n\ntest_dataset = CellDataset(image_ids,df,CFG.TEST_DIR,transforms=DataTransforms.transform_valid(),status='test',resnet=False)\n\ntest_loader = torch.utils.data.DataLoader(test_dataset,batch_size=CFG.train_batch_size,num_workers=CFG.num_workers,shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test(model, test_loader):\n    '''\n    Функция получающая предсказанные маски, соответствующие ID и предсказанные типы клеток. Создание итогового submission.csv\n    '''\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model.to(device)\n    model.eval()\n\n    masks_list = []  # Список для хранения масок и ID\n    predicted_rles = []\n    with torch.no_grad():\n        for images, image_ids in test_loader:\n            images = images.to(device).float()\n\n            # Прямой проход\n            outputs, predicted_cell_type = model(images)\n            masks = (outputs > 0.5).float()  # Применение порога для получения бинарных масок\n            \n            # Добавление маски, ID и предсказанного типа клетки в список\n            for i in range(len(image_ids)):\n                masks_list.append((masks[i], image_ids[i], predicted_cell_type[i]))\n                predicted_index = torch.argmax(predicted_cell_type[i])\n                predicted_class = list(Cell_type_encoding.keys())[predicted_index]\n                #print(f\"Predicted cell type for {image_ids[i]}: {predicted_class}\")\n                predicted_rle = mask_to_rle(masks[i])\n                predicted_rles.append(predicted_rle)\n    df_id_rle = pd.DataFrame({'id': image_ids, 'predicted': predicted_rles})\n    df_id_rle.to_csv('submission.csv', index=False)\n   \n    return masks_list","metadata":{"execution":{"iopub.status.busy":"2023-06-18T03:52:07.349854Z","iopub.execute_input":"2023-06-18T03:52:07.350935Z","iopub.status.idle":"2023-06-18T03:52:07.362241Z","shell.execute_reply.started":"2023-06-18T03:52:07.350895Z","shell.execute_reply":"2023-06-18T03:52:07.361192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Предсказание и отрисовка резуальтата**","metadata":{}},{"cell_type":"code","source":"masks_list = test(model, test_loader)\n\nfor i, (masks, image_ids, predicted_cell_type) in enumerate(masks_list):\n    if masks.numel() == 0:  # Check if masks is empty\n        continue\n   \n    # Преобразование масок в массивы NumPy\n    masks = np.squeeze(masks) # Удаление размерности num_classes (если есть)\n    masks = masks.cpu().numpy()  # Преобразование в массив NumPy\n    full_masks = cv2.resize(masks, original_size)\n    predicted_index = torch.argmax(predicted_cell_type, dim=-1)\n    predicted_class = list(Cell_type_encoding.keys())[predicted_index.item()]\n    \n    # Отображение каждой маски\n    plt.figure(figsize=(12, 6))\n    plt.subplot(1, 2, 1)\n    plt.imshow(cv2.imread(CFG.TEST_DIR + image_ids + '.png'))\n    plt.axis(\"off\")\n    plt.title(f'Оригинал Изображения: {image_ids}')\n    plt.subplot(1, 2, 2)\n    plt.imshow(cv2.imread(CFG.TEST_DIR + image_ids + '.png'))\n    plt.imshow(full_masks, alpha=0.2)\n    plt.title(f\"Предсказанная маска {image_ids} Предсказанный тип: {predicted_class}\")\n    plt.axis('off')\n    plt.tight_layout()\n    plt.show()\n \n    ","metadata":{"execution":{"iopub.status.busy":"2023-06-18T04:28:01.440682Z","iopub.execute_input":"2023-06-18T04:28:01.441400Z","iopub.status.idle":"2023-06-18T04:28:03.674324Z","shell.execute_reply.started":"2023-06-18T04:28:01.441366Z","shell.execute_reply":"2023-06-18T04:28:03.672224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Реализуем модель ResNet101**\nResNet101 всего есть 4 основных блока:\nПервый блок (self.layer0): Состоит из 2 сверточных слоев.\nВторой блок (self.layer1): Состоит из 3 сверточных слоев.\nТретий блок (self.layer2): Состоит из 23 сверточных слоев.\nЧетвёртый блок (self.layer3): Состоит из 36 сверточных слоев.","metadata":{}},{"cell_type":"code","source":"class CellTypeEncoder(nn.Module):\n    '''\n    Линейные слои для определения типа клетки\n    '''\n    def __init__(self, in_features, num_classes,dropout=True):\n        super(CellTypeEncoder, self).__init__()\n\n        hidden_size1 = 512\n        hidden_size2 = 256\n        hidden_size3 = 128\n        hidden_size4 = 64\n        \n        self.fc1 = nn.Linear(in_features, hidden_size1)\n        #self.dropout1 = nn.Dropout(p=0.2) \n        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n        self.fc3 = nn.Linear(hidden_size2, hidden_size3)\n        self.dropout1 = nn.Dropout(p=0.2) \n        self.fc4 = nn.Linear(hidden_size3, hidden_size4)\n        self.fc5 = nn.Linear(hidden_size4, num_classes)\n        self.selu = nn.SELU()\n    def forward(self, x):\n        x = self.selu(self.fc1(x))\n        #x = self.dropout1(x)\n        x = self.selu(self.fc2(x))\n        x = self.dropout1(x)\n        x = self.selu(self.fc3(x))\n        #x = self.dropout1(x)\n        x = self.selu(self.fc4(x))\n        x = self.fc5(x)\n        return x\n    \nclass UNetWithResNet(nn.Module):\n    def __init__(self, in_channels=1, out_channels=1, num_classes=3, encoder_cell_features=2048, dropout=True):\n        super(UNetWithResNet, self).__init__()\n\n        self.TLmodel = models.resnet101()\n        self.TLlayers = list(self.TLmodel.children())\n\n        # Encoder\n        self.layer0 = nn.Sequential(*self.TLlayers[:4]) # Первые 4 слоя Resnet(Свертки нормализация пулинг)\n        self.layer0_1 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1), nn.SELU())#,nn.Dropout(p=0.2)) #сверта SELU\n        self.layer1 = nn.Sequential(*self.TLlayers[4:5]) # Пятый слой\n        self.layer1_1 = nn.Sequential(nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1), nn.SELU())#,nn.Dropout(p=0.2))\n        self.layer2 = self.TLlayers[5]\n        self.layer2_1 = nn.Sequential(nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1), nn.SELU())#,nn.Dropout(p=0.2))\n        self.layer3 = self.TLlayers[6]\n        self.layer3_1 = nn.Sequential(nn.Conv2d(1024, 1024, kernel_size=3, stride=1, padding=1), nn.SELU())#,nn.Dropout(p=0.2))\n        self.layer4 = self.TLlayers[7]\n        self.layer4_1 = nn.Sequential(nn.Conv2d(2048, 2048, kernel_size=3, stride=1, padding=1), nn.SELU())#,nn.Dropout(p=0.2))\n\n        # Decoder\n        self.decoder3 = nn.Sequential(nn.Conv2d(2048+1024, 1024, kernel_size=3, padding=1), nn.SELU())#,nn.Dropout(p=0.2))\n        self.decoder2 = nn.Sequential(nn.Conv2d(512+1024, 512, kernel_size=3, padding=1), nn.SELU())#,nn.Dropout(p=0.2))\n        self.decoder1 = nn.Sequential(nn.Conv2d(256+512, 512, kernel_size=3, padding=1), nn.SELU())#,nn.Dropout(p=0.2))\n        self.decoder0 = nn.Sequential(nn.Conv2d(64+512, 256, kernel_size=3, padding=1), nn.SELU())#,nn.Dropout(p=0.2))\n\n        # Final layers\n        self.final_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n        self.sigmoid = nn.Sigmoid()\n\n        # Upsampling\n        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n\n        # Cell Type Encoder\n        self.cell_type_encoder = CellTypeEncoder(encoder_cell_features, num_classes, dropout=True)\n        self.softmax = nn.Softmax(dim=1)\n\n        # Original size convolutions\n        self.conv_original_size0 = nn.Sequential(nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1), nn.SELU())\n        self.conv_original_size1 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1), nn.SELU())\n        self.conv_original_size2 = nn.Sequential(nn.Conv2d(256+64, 64, kernel_size=3, stride=1, padding=1), nn.SELU())\n        \n        #Dropout\n        self.dropout = nn.Dropout(p=0.2)\n\n    def forward(self, x):\n        x_original = self.conv_original_size0(x)\n        x_original = self.conv_original_size1(x_original)\n        enc0 = self.layer0(x)\n        enc1 = self.layer1(enc0)\n        enc2 = self.layer2(enc1)\n        enc3 = self.layer3(enc2)\n        enc4 = self.layer4(enc3)\n        dec4 = self.layer4_1(enc4)\n        \n        dec4 = self.dropout(dec4)\n        \n        dec4 = self.upsample(dec4)\n        enc3 = self.layer3_1(enc3)\n        dec4 = torch.cat([dec4, enc3], dim=1)\n        dec3 = self.decoder3(dec4)\n        \n        dec3 = self.upsample(dec3)\n        enc2 = self.layer2_1(enc2)\n        dec3 = torch.cat([dec3, enc2], dim=1)\n        dec2 = self.decoder2(dec3)\n        \n        dec2 = self.upsample(dec2)\n        enc1 = self.layer1_1(enc1)\n        dec2 = torch.cat([dec2, enc1], dim=1)\n        dec1 = self.decoder1(dec2)\n        \n        dec1 = self.upsample(dec1)\n        enc0 = self.layer0_1(enc0)\n        enc0_upsampled = self.upsample(enc0)\n        dec0 = torch.cat([dec1, enc0_upsampled], dim=1)\n        dec0 = self.decoder0(dec0)\n        \n        dec0 = self.upsample(dec0)\n        decf = torch.cat([dec0, x_original], dim=1)\n        #decf = self.dropout(decf)\n        decf = self.conv_original_size2(decf)\n        decf = self.dropout(decf)\n        mask_output = self.final_conv(decf)\n        mask_output = self.sigmoid(mask_output)\n\n        cell_type_features = torch.mean(enc4, dim=(2, 3))\n        cell_type_output = self.cell_type_encoder(cell_type_features)\n        cell_type_output = self.softmax(cell_type_output)\n\n        return mask_output, cell_type_output","metadata":{"execution":{"iopub.status.busy":"2023-06-18T01:49:31.735595Z","iopub.execute_input":"2023-06-18T01:49:31.735990Z","iopub.status.idle":"2023-06-18T01:49:31.767735Z","shell.execute_reply.started":"2023-06-18T01:49:31.735956Z","shell.execute_reply":"2023-06-18T01:49:31.766725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''def dice_coefficient(predicted, target):\n    smooth = 1e-5\n\n    predicted_flat = predicted.view(-1)\n    target_flat = target.view(-1)\n\n    intersection = (predicted_flat * target_flat).sum()\n    union = predicted_flat.sum() + target_flat.sum()\n\n    dice = (2.0 * intersection + smooth) / (union + smooth)\n    return dice","metadata":{"execution":{"iopub.status.busy":"2023-06-17T13:46:16.267123Z","iopub.execute_input":"2023-06-17T13:46:16.267507Z","iopub.status.idle":"2023-06-17T13:46:16.274148Z","shell.execute_reply.started":"2023-06-17T13:46:16.267477Z","shell.execute_reply":"2023-06-17T13:46:16.273185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n# ****Создание загрузчиков и Обучение на предобученной ResNet101****\n**(Перед запуском лучше поменять число эпох в CFG с 19 на например 39)**","metadata":{}},{"cell_type":"code","source":"#wandb.login(key=\")\nos.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\"\nos.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n# Создание датасета и загрузчиков\nids = df['id'].unique()\nfrom sklearn.model_selection import train_test_split\ntrain_ids, val_ids = train_test_split(ids, test_size=0.2, random_state=CFG.seed)\ntrain_loader, valid_loader = train_and_valid_dataloaders(df, train_ids, val_ids,resnet=True)\n\n# Создание модели и обучение\n#model = UNetWithCellType(dropout=True)\nmodelRN = UNetWithResNet(dropout=True)\ntrain(modelRN,train_loader, valid_loader, CFG.num_epochs, CFG.lr)#,wandb=True)","metadata":{"execution":{"iopub.status.busy":"2023-06-18T02:11:58.113784Z","iopub.execute_input":"2023-06-18T02:11:58.114152Z","iopub.status.idle":"2023-06-18T02:50:51.670532Z","shell.execute_reply.started":"2023-06-18T02:11:58.114124Z","shell.execute_reply":"2023-06-18T02:50:51.669291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Тестовый датасет и отриcовка результатов**","metadata":{}},{"cell_type":"code","source":"# Создание тестового датасета и загрузчиков\n\nfiles = os.listdir(CFG.TEST_DIR)\nimage_ids = np.array([os.path.splitext(file)[0] for file in files])\nids = []\nrle_test_preds = []\noriginal_size = (704, 520)  \n\ntest_dataset = CellDataset(image_ids,df,CFG.TEST_DIR,transforms=DataTransforms.transform_valid(),status='test',resnet=True)\n\ntest_loader = torch.utils.data.DataLoader(test_dataset,batch_size=CFG.train_batch_size,num_workers=CFG.num_workers,shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-06-18T02:51:33.095908Z","iopub.execute_input":"2023-06-18T02:51:33.096266Z","iopub.status.idle":"2023-06-18T02:51:33.103657Z","shell.execute_reply.started":"2023-06-18T02:51:33.096229Z","shell.execute_reply":"2023-06-18T02:51:33.102637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"masks_list = test(modelRN, test_loader)\n\nfor i, (masks, image_ids, predicted_cell_type) in enumerate(masks_list):\n    if masks.numel() == 0:  # Check if masks is empty\n        continue\n   \n    # Преобразование масок в массивы NumPy\n    masks = np.squeeze(masks) # Удаление размерности num_classes (если есть)\n    masks = masks.cpu().numpy()  # Преобразование в массив NumPy\n    full_masks = cv2.resize(masks, original_size)\n    predicted_index = torch.argmax(predicted_cell_type, dim=-1)\n    predicted_class = list(Cell_type_encoding.keys())[predicted_index.item()]\n    \n    # Отображение каждой маски\n    plt.figure(figsize=(12, 6))\n    plt.subplot(1, 2, 1)\n    plt.imshow(cv2.imread(CFG.TEST_DIR + image_ids + '.png'))\n    plt.axis(\"off\")\n    plt.title(f'Оригинал Изображения: {image_ids}')\n    plt.subplot(1, 2, 2)\n    plt.imshow(cv2.imread(CFG.TEST_DIR + image_ids + '.png'))\n    plt.imshow(full_masks, alpha=0.2)\n    plt.title(f\"Предсказанная маска {image_ids} Предсказанный тип: {predicted_class}\")\n    plt.axis('off')\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-18T02:51:55.024798Z","iopub.execute_input":"2023-06-18T02:51:55.025194Z","iopub.status.idle":"2023-06-18T02:51:57.402641Z","shell.execute_reply.started":"2023-06-18T02:51:55.025152Z","shell.execute_reply":"2023-06-18T02:51:57.401716Z"},"trusted":true},"execution_count":null,"outputs":[]}]}